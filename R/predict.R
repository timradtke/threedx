#' Draw forecast sample paths from a fitted 3DX model
#' 
#' @details While `observation_driven` can be effective at forecasting wide
#'   ranges of time series, the induced forecast distribution collapses to a
#'   single point as `alpha`, `alpha_seasonal`, and `alpha_seasonal_decay`
#'   values tend towards 1. While the corresponding point prediction may still
#'   be optimal, the uncertainty in the forecast is likely underestimated.
#'   
#'   For example, if `alpha = 0.98`, `alpha_seasonal=0`, and
#'   `alpha_seasonal_decay=0`, the resulting forecast distribution assigns 98%
#'   probability to the most recent observation, thus collapsing most prediction
#'   intervals onto that point. This can be highly unrealistic for time series
#'   whose level is changing rapidly and therefore require large `alpha` values.
#'   
#'   To circumvent this issue, one can design certain conditions under
#'   which `observation_driven` is set to `TRUE`. For example, using
#'   [k_largest_weights_sum_to_less_than_p_percent()], one can check that the
#'   learned model assigns weight to at least a few observations, and only then
#'   set `observation_driven=TRUE`. However, if the underlying time series is
#'   truly a random walk, `observation_driven=TRUE` will always be a poor choice
#'   as it limits the range of possible future values too much.
#' 
#' @param object A fitted model object of class `threedx`
#' @param horizon An integer defining the forecast horizon
#' @param n_samples An integer defining the number of sample paths to draw
#' @param observation_driven Logical; if `TRUE`, sample paths are generated by
#'   drawing from weighted historical observations directly instead of adding
#'   innovation noise on the current mean forecast. This is similar to the
#'   Non-Parametric Time Series forecaster (NPTS) described in
#'   "GluonTS: Probabilistic Time Series Models in Python" (2019) by Alexandrov
#'   et al. (see <https://arxiv.org/abs/1906.05264>). If `FALSE`, sample paths
#'   will be generated by adding innovation noise on top of the current weighted
#'   average forecast.
#' @param innovation_function A function with arguments `n` and `errors`. Must
#'   be able to handle additional parameters via `...` to allow for potential
#'   future changes in the set of arguments passed to
#'   `innovation_function` by [predict.threedx()]. For examples, see
#'   [draw_normal_with_drift()] or [draw_bootstrap_weighted()].
#'   The provided `innovation_function` must return a numeric vector of length
#'   `n` that contains i.i.d samples that can be used for any sample path and
#'   forecast horizon.
#'   This argument is ignored when `observation_driven=TRUE`.
#' @param postprocess A function that is applied on a numeric vector of
#'   drawn samples for a single step-ahead before the samples are used to
#'   update the state of the model, and before outliers are removed
#'   (if applicable). By default equal to `identity()`, but could also
#'   be something like `function(x) pmax(x, 0)` to enforce a lower bound of 0,
#'   or any other transformation of interest that returns a numeric vector of
#'   equal length as that of the input.
#'   Note that this can cause arbitrary errors caused by the author of the
#'   function provided to `postprocess`.
#'   For examples, see [to_non_negative_with_identical_mean()] or
#'   [to_moment_matched_nbinom()].
#' @param ... Additional arguments passed to `innovation_function`
#' 
#' @return 
#' A forecast object of class `threedx_paths`, which is a list of:
#' * A `paths` numeric matrix of dimensions `n_samples`-times-`horizon`. The
#'   matrix stores the forecast sample paths that are the probabilistic forecast
#'   returned by the `threedx` model. Aggregate across the first dimension to
#'   derive expectations of the forecast distribution, aggregate across the
#'   second dimension to derive sums over the forecast horizon.
#' * The input `horizon` argument
#' * The input `n_samples` argument
#' * The input `observation_driven` argument
#' * The model `model` provided via `object`, an object of class `threedx`
#' 
#' @seealso [learn_weights()], [k_largest_weights_sum_to_less_than_p_percent()],
#'   [loss_mae()], [loss_rmse()], [draw_normal_with_zero_mean()],
#'   [draw_bootstrap()], [to_non_negative_with_identical_mean()],
#'   [to_moment_matched_nbinom()]
#' 
#' @export
#' @examples
#' set.seed(9284)
#' y <- stats::rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi((5 + 1:55 )/ 6)))
#' 
#' model <- learn_weights(
#'   y = y,
#'   alphas_grid = list_sampled_alphas(
#'     n_target = 1000L,
#'     include_edge_cases = TRUE
#'   ),
#'   period_length = 12L,
#'   loss_function = loss_mae
#' )
#' 
#' forecast_observation_driven <- predict(
#'   object = model,
#'   horizon = 12L,
#'   n_samples = 2500L,
#'   observation_driven = TRUE
#' )
#' 
#' if (require("ggplot2")) {
#'   autoplot(forecast_observation_driven)
#' }
#' 
#' forecast_latent <- predict(
#'   object = model,
#'   horizon = 12L,
#'   n_samples = 2500L,
#'   observation_driven = FALSE,
#'   innovation_function = draw_bootstrap
#' )
#' 
#' if (require("ggplot2")) {
#'   autoplot(forecast_latent)
#' }
#' 
#' forecast_latent_with_postprocessing <- predict(
#'   object = model,
#'   horizon = 12L,
#'   n_samples = 2500L,
#'   observation_driven = FALSE,
#'   innovation_function = draw_normal_with_zero_mean,
#'   postprocess = function(x) round(pmax(x, 0))
#' )
#' 
#' if (require("ggplot2")) {
#'   autoplot(forecast_latent_with_postprocessing)
#' }
#' 
predict.threedx <- function(object,
                            horizon,
                            n_samples,
                            observation_driven,
                            innovation_function,
                            postprocess = identity,
                            ...) {
  
  checkmate::assert_class(x = object, classes = "threedx")
  checkmate::assert_logical(
    x = observation_driven, len = 1, any.missing = FALSE
  )
  checkmate::assert_integerish(
    x = n_samples, lower = 1, any.missing = FALSE, len = 1
  )
  
  y_m <- matrix(
    data = object$y,
    nrow = n_samples,
    ncol = object$n,
    byrow = TRUE
  )
  
  if (observation_driven) {
    paths <- predict_with_observations(
      y_m = y_m,
      object = object,
      horizon = horizon,
      n_samples = n_samples,
      postprocess = postprocess
    )
  } else {
    paths <- predict_with_state(
      y_m = y_m,
      object = object,
      horizon = horizon,
      n_samples = n_samples,
      innovation_function = innovation_function,
      postprocess = postprocess,
      ...
    )
  }
  
  result <- structure(
    list(
      paths = paths,
      model = object,
      horizon = horizon,
      n_samples = n_samples,
      observation_driven = observation_driven
    ),
    class = "threedx_paths"
  )
  
  return(result)
}

#' Generate sample paths using observed values
#' 
#' @keywords internal
predict_with_observations <- function(y_m,
                                      object,
                                      horizon,
                                      n_samples,
                                      postprocess) {
  
  checkmate::assert_integerish(
    x = horizon, lower = 1, len = 1, any.missing = FALSE
  )
  checkmate::assert_integerish(
    x = n_samples, lower = 1, len = 1, any.missing = FALSE
  )
  checkmate::assert_function(x = postprocess, null.ok = FALSE, nargs = 1)
  
  y_hat_m <- matrix(
    data = NA_real_,
    nrow = n_samples,
    ncol = horizon
  )
  
  for (idx in seq_len(horizon)) {
    sample_indices <- sample(
      x = seq_len(object$n + idx - 1),
      size = n_samples,
      replace = TRUE,
      prob = weights_threedx(
        alpha = object$alpha,
        alpha_seasonal = object$alpha_seasonal,
        alpha_seasonal_decay = object$alpha_seasonal_decay,
        n = object$n + idx - 1,
        period_length = object$period_length
      )
    )
    
    tmp_y_m <- cbind(y_m, y_hat_m[, seq_len(idx-1), drop = FALSE])
    
    for (sample_idx in seq_len(n_samples)) {
      y_hat_m[sample_idx, idx] <- from_and_to_matrix_column(
        data = tmp_y_m[sample_idx, sample_indices[sample_idx]],
        FUN = postprocess
      )
    }
  }
  
  return(y_hat_m)
}

#' Generate sample paths using latent state
#' 
#' @keywords internal
predict_with_state <- function(y_m,
                               object,
                               horizon,
                               n_samples,
                               innovation_function,
                               postprocess,
                               ...) {
  
  checkmate::assert_integerish(
    x = horizon, lower = 1, len = 1, any.missing = FALSE
  )
  checkmate::assert_integerish(
    x = n_samples, lower = 1, len = 1, any.missing = FALSE
  )
  checkmate::assert_function(x = postprocess, null.ok = FALSE, nargs = 1)
  checkmate::assert_function(
    x = innovation_function,
    args = c("n", "errors"),
    ordered = TRUE
  )
  
  if (length(object$residuals) == 0L) {
    stop("The `object$residuals` are of length zero, can't generate innovation
         noise.")
  }
  
  if (all(is.na(object$residuals))) {
    stop("All `residuals` available in `object` are missing, can't generate
         innovation noise.")
  }
  
  y_hat_m <- matrix(
    data = innovation_function(
      n = horizon * n_samples,
      errors = stats::na.omit(object$residuals),
      ...
    ),
    nrow = n_samples,
    ncol = horizon
  )
  
  for (idx in seq_len(horizon)) {
    y_hat_m[, idx] <- from_and_to_matrix_column(
      data = y_hat_m[, idx] +
        cbind(y_m, y_hat_m[, seq_len(idx-1), drop = FALSE]) %*%
        matrix(
          data = weights_threedx(
            alpha = object$alpha,
            alpha_seasonal = object$alpha_seasonal,
            alpha_seasonal_decay = object$alpha_seasonal_decay,
            n = object$n + idx - 1,
            period_length = object$period_length
          ),
          ncol = 1
        ),
      FUN = postprocess
    )
  }
  
  return(y_hat_m)
}

from_and_to_matrix_column <- function(data, FUN) {
  matrix(
    data = FUN(as.numeric(data)),
    ncol = 1
  )
}
