[{"path":"http://timradtke.github.io/threedx/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 threedx authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://timradtke.github.io/threedx/articles/define_custom_innovation_functions.html","id":"independence-of-innovations","dir":"Articles","previous_headings":"","what":"Independence of Innovations","title":"Define Custom Innovation Functions","text":"predict.threedx(), independently drawn innovations used construct sample paths iteratively. first n_samples innovations added top point prediction horizon one. resulting n_samples potential future observations combined past observations weighted model weights generate point prediction horizon two. Next, second batch n_samples innovations added point prediction horizon two, process repeats. iterative behavior, sample path exhibit autocorrelation depending fitted model—despite original innovations independent samples. time, different sample paths independent .","code":""},{"path":"http://timradtke.github.io/threedx/articles/define_custom_innovation_functions.html","id":"a-bit-of-inspiration","dir":"Articles","previous_headings":"","what":"A Bit of Inspiration","title":"Define Custom Innovation Functions","text":"residuals provided, one can use draw non-parametric bootstrap: since errors provided chronological order, can use index arbitrary things: sample based errors recent period , assign weights residuals sampling, done draw_bootstrap_weighted().","code":"print(draw_bootstrap) #> function (n, errors, ...)  #> { #>     checkmate::assert_integerish(x = n, lower = 1, any.missing = FALSE,  #>         len = 1) #>     checkmate::assert_numeric(x = errors, finite = TRUE, any.missing = FALSE,  #>         min.len = 1) #>     if (length(errors) == 1L) { #>         return(rep(errors, times = n)) #>     } #>     sample(x = errors, size = n, replace = TRUE, prob = NULL) #> } #> <bytecode: 0x558a049efeb8> #> <environment: namespace:threedx>"},{"path":"http://timradtke.github.io/threedx/articles/define_custom_loss_functions.html","id":"constructing-a-loss-function","dir":"Articles","previous_headings":"","what":"Constructing a Loss Function","title":"Define Custom Loss Functions","text":"time writing, learn_weights() passes three arguments loss function: numeric vector observed actuals y without missing values numeric vector one-step-ahead predictions y_hat length y also without missing values arguments ... might provided future loss function, access y y_hat course essential compute errors, assign weights errors. return, learn_weights() expects receive non-missing numeric scalar value loss function. scalars minimized across parameter combinations defined alphas_grid choose optimal parameter combination. One simplest possible loss functions can used mean absolute error loss function. implementation threedx straightforward: can go complex. example, threedx provides loss assigns weight (based size observation) absolute error taking mean: Wether useful loss function depend context. goes show lot flexibility. Another idea define function ever takes 20 recent observations account: one applies moving averages observations predictions first, one takes account observations seasonal period next one-step-ahead prediction perform, …","code":"print(loss_mae) #> function (y_hat, y, ...)  #> { #>     mean(abs(y - y_hat)) #> } #> <bytecode: 0x5606f2bd5b08> #> <environment: namespace:threedx> loss_mae(y_hat = c(5, -3, 2), y = c(1, 1, -2)) #> [1] 4 print(loss_mae_with_observation_weight) #> function (y_hat, y, ...)  #> { #>     sqrt(mean(abs(y - y_hat) * pmax(y, abs(y - y_hat)))) #> } #> <bytecode: 0x5606f2f4a170> #> <environment: namespace:threedx> loss_mae_twenty_most_recent <- function(y_hat, y, ...) {   loss_mae(utils::tail(y_hat, 20), utils::tail(y, 20), ...) }"},{"path":"http://timradtke.github.io/threedx/articles/forecasting_trends.html","id":"the-innovation-function-is-not-a-panacea","dir":"Articles","previous_headings":"","what":"The Innovation Function Is Not A Panacea","title":"Forecasting Trends with `threedx`","text":"choice innovation function remedy missing trend component example, doesn’t work quite neatly cases. using innovation function doesn’t enforce zero-mean, forecast can improved time series consist strong mostly linear trend. However, trend uniform across past observations, seasonal components well, forecast can much trickier. soon model tries compensate trend way training (instead using alpha close 1), thereby messes clean prediction seasonal component, much can fixed innovation function choice. Consider following extreme example make problem tangible. forecast monthly seasonal time series trends upward every year three additional units. make relationship trend, model, residuals clear, don’t add noise component:  First, note threedx can forecast seasonal component perfectly ’s component:  However, trend seasonality combined, model training results unfortunate parameter choice relinquishes perfect seasonality prediction accompany trend desperate fashion. reason loss function: mean absolute error (used via loss_mae()) reduced trading error due trend error due seasonality. accept bias one-step-ahead predictions remain due trend models predict seasonality perfectly.  can recover optimal model choice (combination drifting innovation function) using loss function ignores bias. Let’s redefine mean absolute error, removing mean bias: Using loss_mae_ignoring_bias() instead loss_mae(), model perfectly removes seasonal error chosen trend bias ignored training. prediction, bias compensated innovations drift.  , unlikely panacea.","code":"component_season <- rep(c(0,1,2,3,4,5,6,5,4,3,2,1), times = 5) * 5 component_trend <- 1:60  y <- component_season + component_trend threedx::learn_weights(   y = component_season,   period_length = 12L,   alphas_grid = list_sampled_alphas(include_edge_cases = TRUE),   loss_function = loss_mae ) |>   predict(     horizon = 24L,     n_samples = 1000L,     observation_driven = FALSE,     innovation_function = draw_normal_with_zero_mean   ) |>   autoplot() threedx::learn_weights(   y = y,   period_length = 12L,   alphas_grid = list_sampled_alphas(include_edge_cases = TRUE),   loss_function = loss_mae ) |>   predict(     horizon = 12L,     n_samples = 1000L,     observation_driven = FALSE,     innovation_function = draw_normal_with_drift   ) |>   autoplot() loss_mae_ignoring_bias <- function(y_hat, y, ...) {   residuals <- y - y_hat   residuals_zero_bias <- residuals - mean(residuals)   mean(abs(residuals_zero_bias)) } threedx::learn_weights(   y = y,   period_length = 12L,   alphas_grid = list_sampled_alphas(include_edge_cases = TRUE),   loss_function = loss_mae_ignoring_bias ) |>   predict(     horizon = 12L,     n_samples = 1000L,     observation_driven = FALSE,     innovation_function = draw_normal_with_drift   ) |>   autoplot()"},{"path":"http://timradtke.github.io/threedx/articles/generating_diverse_weights.html","id":"parameter-space-and-weights-space","dir":"Articles","previous_headings":"","what":"Parameter Space and Weights Space","title":"Generating Diverse Weights for Training","text":"training threedx model, parameters alpha, alpha_seasonal, alpha_seasonal_decay translated weights assigned every index observed time series. example, given time series n = 50 observations period length period_length = 12L, parameter choices alpha = 0.9, alpha_seasonal = 0.9, alpha_seasonal_decay = 0.05, resulting weights :  expect , let model train wide range possible parameter combinations, try many different combinations weights cover range possible models, thereby find good one. following set parameters–end possible alpha_seasonal spectrum–results nearly identical weights:  third combination parameters alpha_seasonal_decay opposite end allowed range:  Thus, large changes parameter space necessarily imply large changes weights space. Since weights space ultimately care , since like cover weights space perhaps uniformly default, means covering parameter space uniform manner suboptimal.","code":"weights_first <- weights_threedx(   alpha = 0.9,   alpha_seasonal = 0.9,   alpha_seasonal_decay = 0.05,   n = 50L,   period_length = 12L )  round(tail(weights_first, 13L), 4) #>  [1] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 #> [11] 0.0001 0.0099 0.9900 weights_second <- weights_threedx(   alpha = 0.9,   alpha_seasonal = 0.1,   alpha_seasonal_decay = 0.05,   n = 50L,   period_length = 12L )  round(tail(weights_second, 13L), 4) #>  [1] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0001 0.0007 #> [11] 0.0074 0.0819 0.9100 weights_third <- weights_threedx(   alpha = 0.9,   alpha_seasonal = 0.1,   alpha_seasonal_decay = 0.95,   n = 50L,   period_length = 12L )  round(tail(weights_third, 13L), 4) #>  [1] 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0001 0.0007 #> [11] 0.0074 0.0819 0.9100"},{"path":"http://timradtke.github.io/threedx/articles/generating_diverse_weights.html","id":"the-impact-of-alpha","dir":"Articles","previous_headings":"","what":"The Impact of alpha","title":"Generating Diverse Weights for Training","text":"indicated examples , alpha parameter can overshadow two parameter choices. Depending length period time series, alpha assign much weight recent one, two, three indices simply weight left indices come later—heavily impacted choice alpha_seasonal alpha_seasonal_decay. can render grid generated default list_sampled_alphas() function wasteful, uniformly samples parameter space, thereby trying many different combinations alpha_seasonal alpha_seasonal_decay alpha values lead essentially equal set weights. Let’s take look happen usual call list_sampled_alphas() samples entire [0, 1]-cube uniformly. code chunk starts creating alphas_grid. alphas_grid created, generate set 1000 weights implied 1000 different parameter combinations. 1000 implied sets weights, take three weights assigned three recent observations sum , resulting vector weight_three_most_recent_indices length 1000. value summarizes probability parameter set assigns three recent indices. graph shows choice alpha drives (share total) weight assigned three recent observations alone. Since three parameters sampled uniformly independently , roughly 25% parameter combinations plotted alpha larger 0.75, 50% alpha larger 0.5, . Consequently, half parameter combinations assign 80% weight three recent observations, roughly 25% parameter combinations even assign nearly 100% weight three recent indices. 1000 parameter combinations implies different model, thus different predictions, leads different forecast performance. since half parameter combinations imply similar weights, three recent observations ones impacting forecast, half models evaluated produce similar forecasts.","code":"alphas_grid <- list_sampled_alphas(   n_target = 1000L,   alpha_lower = 0.0001,   alpha_upper = 0.9999,   alpha_seasonal_lower = 0.0001,   alpha_seasonal_upper = 0.9999,   alpha_seasonal_decay_lower = 0.0001,   alpha_seasonal_decay_upper = 0.9999,   oversample_lower = 0,   oversample_upper = 0   )  weight_three_most_recent_indices <- rowSums(   threedx:::weights_threedx_vec(     alphas = alphas_grid$alpha,     alphas_seasonal = alphas_grid$alpha_seasonal,     alphas_seasonal_decay = alphas_grid$alpha_seasonal_decay,     n = 50L,     period_length = 12L   )[, 48:50] )"},{"path":"http://timradtke.github.io/threedx/articles/generating_diverse_weights.html","id":"generating-more-diverse-weights","dir":"Articles","previous_headings":"","what":"Generating More Diverse Weights","title":"Generating Diverse Weights for Training","text":"learn_weights(), model trained via grid search. provided alphas_grid evaluated, loss minimizing parameter combination chosen. fast performance, want keep alphas_grid small possible. improved forecast performance, want try wide alphas_grid possible. especially don’t want try parameter combinations imply similar weights multiple times close duplicate. Given , don’t need try different values alpha_seasonal alpha_seasonal_decay different alpha values. soon alpha moderately large, weights essentially simple exponential smoothing anyway. Something like following help. First, create simple sequence moderately large alpha values (, larger 0.50) holding two constant: Next, draw large set random values three parameters keep alpha 0.25: Finally take edge case parameter combinations union three different sets: visible resulting graph, now lot samples smaller weight levels three recent observations. help leave samples parameter combinations model interesting combinations seasonal patterns.","code":"alphas_grid_ses <- data.frame(   alpha = seq(0.50, 1, by = 0.01),   alpha_seasonal = 0,   alpha_seasonal_decay = 0 ) alphas_grid <- data.frame(   alpha = rbeta(n = 1000, 1, 2) * 0.50,   alpha_seasonal = rbeta(n = 1000, 0.75, 0.75),   alpha_seasonal_decay = rbeta(n = 1000, 0.7, 0.8) ) alphas_grid <- unique(   rbind(     list_edge_alphas(),     alphas_grid_ses,     alphas_grid     )   )  weight_three_most_recent_indices <- rowSums(   threedx:::weights_threedx_vec(     alphas = alphas_grid$alpha,     alphas_seasonal = alphas_grid$alpha_seasonal,     alphas_seasonal_decay = alphas_grid$alpha_seasonal_decay,     n = 50L,     period_length = 12L   )[, 48:50] )"},{"path":"http://timradtke.github.io/threedx/articles/threedx.html","id":"threedx-3dx","dir":"Articles","previous_headings":"","what":"threedx (3DX)","title":"Get Started","text":"Use 3DX generate interpretable probabilistic forecasts purely weighting values observed time series. ’s unique 3DX can used derive forecasts based “latent state” also observation-driven, drawing future realizations purely observed values. can effective count intermittent series. 3DX builds ideas NPTS model described Alexandrov et al. (2019). sampling distribution combination three components: first weighs observations exponentially, second weighs observations within seasonal period exponentially, third weighs seasonal periods time exponentially.","code":""},{"path":"http://timradtke.github.io/threedx/articles/threedx.html","id":"get-started","dir":"Articles","previous_headings":"threedx (3DX)","what":"Get Started","title":"Get Started","text":"Let’s generate sparse monthly time series strong seasonality. forecast series, first fit model learning appropriate weights given period length series’ seasonality. Afterwards, model can used derive forecast using R’s predict() method. ggplot2 available, can use autoplot() visualize forecast object:  native output 3DX model forecast sample paths, can accessed via forecast$paths. Visualize () instead quantile predictions specifying method \"paths\":","code":"y <- rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(6:59 / 6))) library(threedx)  model <- threedx::learn_weights(   y = y,   period_length = 12L,   alphas_grid = threedx::list_sampled_alphas(     n_target = 1000L,     include_edge_cases = TRUE   ),   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 2500L,   observation_driven = TRUE ) library(ggplot2) autoplot(forecast) autoplot(forecast, method = \"paths\", n = 5)"},{"path":"http://timradtke.github.io/threedx/articles/working_with_forecast_sample_paths.html","id":"summarize-over-sample-paths","dir":"Articles","previous_headings":"","what":"Summarize Over Sample Paths","title":"Working with Forecast Sample Paths","text":"summarize forecast horizon, can compute mean… … quantile… … ask specific questions “probability observation larger zero?”:","code":"round(colMeans(forecast$paths), 1) #>  [1]  5.9  9.8  9.5 11.0  5.3  1.1  0.1  0.0  0.0  0.2  0.3  1.3 round(apply(forecast$paths, 2, quantile, 0.9), 1) #>  [1] 10 12 11 14  7  2  0  0  0  1  1  2 round(apply(forecast$paths, 2, function(x) mean(x > 0)), 2) #>  [1] 0.97 1.00 1.00 1.00 0.97 0.60 0.05 0.01 0.02 0.19 0.24 0.59"},{"path":"http://timradtke.github.io/threedx/articles/working_with_forecast_sample_paths.html","id":"summarize-over-horizons","dir":"Articles","previous_headings":"","what":"Summarize Over Horizons","title":"Working with Forecast Sample Paths","text":"Similarly, can summarize along n_samples dimension matrix. can ask total value across horizons sample path… … total value six-month period horizon three… … many next twelve months exhibit value zero:","code":"rowSums(forecast$paths)[1:5] #> [1] 39 50 28 34 46 rowSums(   forecast$paths[, 4:9] )[1:5] #> [1] 21 21  9 12 15 rowSums(   forecast$paths == 0 )[1:5] #> [1] 4 5 6 7 6"},{"path":"http://timradtke.github.io/threedx/articles/working_with_forecast_sample_paths.html","id":"summarize-over-horizons-and-sample-paths","dir":"Articles","previous_headings":"","what":"Summarize Over Horizons And Sample Paths","title":"Working with Forecast Sample Paths","text":"Usually, want follow aggregation across horizons aggregation across sample paths. can get median sum next twelve months… … 95% quantile six-month period horizon three… … probability zero value horizons 7 9:","code":"median(rowSums(forecast$paths)) #> [1] 44 quantile(rowSums(forecast$paths[, 4:9]), 0.95) #> 95%  #>  27 mean(rowSums(forecast$paths[, 7:9]) == 0) #> [1] 0.9268"},{"path":"http://timradtke.github.io/threedx/articles/working_with_forecast_sample_paths.html","id":"visualize-sample-path-forecasts","dir":"Articles","previous_headings":"","what":"Visualize Sample Path Forecasts","title":"Working with Forecast Sample Paths","text":"ggplot2 installed, threedx provides two ways visualizing threedx_paths object using autoplot() method. default graph marginal quantiles sample paths forecast horizon many forecast packages provide :  alternative option specified via argument method = \"paths\" visualization individual sample paths lines. Since graph sample paths becomes crowded quickly, default n = 5 randomly chosen paths plotted:  forecast quantiles sometimes give impression model expects flat line future observations. Visualizations sample paths make clear given future scenario anything flat line.","code":"library(ggplot2) autoplot(forecast) autoplot(forecast, method = \"paths\")"},{"path":"http://timradtke.github.io/threedx/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tim Radtke. Author, maintainer.","code":""},{"path":"http://timradtke.github.io/threedx/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Radtke T (2023). threedx: Three-Dimensional Exponential Smoothing Forecasts. R package version 0.0.0.9000,  http://timradtke.github.io/threedx/, https://github.com/timradtke/threedx.","code":"@Manual{,   title = {threedx: Three-Dimensional Exponential Smoothing Forecasts},   author = {Tim Radtke},   year = {2023},   note = {R package version 0.0.0.9000,  http://timradtke.github.io/threedx/},   url = {https://github.com/timradtke/threedx}, }"},{"path":"http://timradtke.github.io/threedx/index.html","id":"threedx-3dx","dir":"","previous_headings":"","what":"Three-Dimensional Exponential Smoothing Forecasts","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"Use 3DX generate interpretable probabilistic forecasts purely weighting values observed time series. ’s unique 3DX can used derive forecasts based “latent state” also observation-driven, drawing future realizations purely observed values. can effective count intermittent series. 3DX builds ideas NPTS model described Alexandrov et al. (2019). sampling distribution combination three components: first weighs observations exponentially, second weighs observations within seasonal period exponentially, third weighs seasonal periods time exponentially.","code":""},{"path":"http://timradtke.github.io/threedx/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"can install development version threedx GitHub : Written pure R, checkmate package direct dependency, installing threedx breeze.","code":"# install.packages(\"devtools\") devtools::install_github(\"timradtke/threedx\")"},{"path":"http://timradtke.github.io/threedx/index.html","id":"get-started","dir":"","previous_headings":"","what":"Get Started","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"Let’s generate sparse monthly time series strong seasonality. forecast series, first fit model learning appropriate weights given period length series’ seasonality. Afterwards, model can used derive forecast using R’s predict() method. ggplot2 available, can use autoplot() visualize forecast object:  native output 3DX model forecast sample paths, can accessed via forecast$paths. Visualize () instead quantile predictions specifying method \"paths\":","code":"y <- rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(6:59 / 6))) library(threedx)  model <- threedx::learn_weights(   y = y,   period_length = 12L,   alphas_grid = threedx::list_sampled_alphas(     n_target = 1000L,     include_edge_cases = TRUE   ),   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 2500L,   observation_driven = TRUE ) library(ggplot2) autoplot(forecast) autoplot(forecast, method = \"paths\", n = 5)"},{"path":"http://timradtke.github.io/threedx/index.html","id":"how-it-works","dir":"","previous_headings":"","what":"How It Works","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"basis 3DX model different ways assigning categorical probability distribution indices observed time series. distribution used 3DX model based combination three components come together weights_threedx(). time series 25 daily observations, weights look like :  3DX weights product three separate weight components.","code":"threedx::weights_threedx(   alpha = 0.1,   alpha_seasonal = 0.75,   alpha_seasonal_decay = 0.25,   n = 25L,   period_length = 7L ) #>  [1] 0.0003333007 0.0003703341 0.0016459293 0.0073152415 0.0433495791 #>  [6] 0.0120415498 0.0033448749 0.0009291319 0.0010323688 0.0045883058 #> [11] 0.0203924702 0.1208442681 0.0335678523 0.0093244034 0.0025901121 #> [16] 0.0028779023 0.0127906768 0.0568474525 0.3368737929 0.0935760536 #> [21] 0.0259933482 0.0072203745 0.0080226383 0.0356561704 0.1584718684"},{"path":"http://timradtke.github.io/threedx/index.html","id":"exponential-weights","dir":"","previous_headings":"How It Works","what":"Exponential Weights","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"simplest weight component assign exponentially decreasing weights. time series daily observations 25 observations, weights look like :  Exponential weights great smoothly interpolate mean forecast alpha = 0 random walk naive forecast alpha = 1. many cases, like model also seasonal component time series. 3DX approaches two additional weight components.","code":"threedx::weights_exponential(alpha = 0.1, n = 25) #>  [1] 0.008593575 0.009548417 0.010609352 0.011788169 0.013097966 0.014553295 #>  [7] 0.016170328 0.017967031 0.019963368 0.022181520 0.024646133 0.027384593 #> [13] 0.030427325 0.033808139 0.037564599 0.041738443 0.046376048 0.051528942 #> [19] 0.057254380 0.063615978 0.070684420 0.078538245 0.087264716 0.096960796 #> [25] 0.107734218"},{"path":"http://timradtke.github.io/threedx/index.html","id":"exponential-seasonal-weights","dir":"","previous_headings":"How It Works","what":"Exponential Seasonal Weights","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"first assigns exponential weights within seasonal period. , consider time series 25 daily observations. suspect weekly seasonality set period_length = 7 deriving seasonal weights: Starting point predicted next (index 26), largest weight assigned index period_length-steps ago, index 19. weight assigned every period_length-steps . Within period, weights decay symmetrically, larger weights closer season predicted. Thus index one step index predicted second highest weight.","code":"threedx::weights_seasonal(alpha_seasonal = 0.75, n = 25, period_length = 7) #>  [1] 0.002941176 0.002941176 0.011764706 0.047058824 0.188235294 0.047058824 #>  [7] 0.011764706 0.002941176 0.002941176 0.011764706 0.047058824 0.188235294 #> [13] 0.047058824 0.011764706 0.002941176 0.002941176 0.011764706 0.047058824 #> [19] 0.188235294 0.047058824 0.011764706 0.002941176 0.002941176 0.011764706 #> [25] 0.047058824"},{"path":"http://timradtke.github.io/threedx/index.html","id":"seasonally-decaying-exponential-weights","dir":"","previous_headings":"How It Works","what":"Seasonally-Decaying Exponential Weights","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"final component assigns exponential weights across seasonal periods constant weights within period: Starting point predicted next (index 26), largest weight assigned index period_length-steps ago, index 19. weight assigned every period_length-steps . Within period, weights decay symmetrically, larger weights closer season predicted. Thus index one step index predicted second highest weight.","code":"threedx::weights_seasonal_decay(   alpha_seasonal_decay = 0.25,   n = 25,   period_length = 7 ) #>  [1] 0.02360140 0.02360140 0.02360140 0.02360140 0.03146853 0.03146853 #>  [7] 0.03146853 0.03146853 0.03146853 0.03146853 0.03146853 0.04195804 #> [13] 0.04195804 0.04195804 0.04195804 0.04195804 0.04195804 0.04195804 #> [19] 0.05594406 0.05594406 0.05594406 0.05594406 0.05594406 0.05594406 #> [25] 0.05594406"},{"path":"http://timradtke.github.io/threedx/index.html","id":"learning-the-optimal-weights","dir":"","previous_headings":"How It Works","what":"Learning the Optimal Weights","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"weights generated weights_threedx() determined three parameters: alpha, alpha_seasonal, alpha_seasonal_decay. three parameters define 3DX model. three parameters can take values 0 1. Larger values lead faster decaying weights, assigning weight recent (seasonal) time indices. Smaller values lead uniform weighting time indices. learn_weights(), optimal parameter combination identified evaluating defined alphas_grid based provided loss_function. Arbitrary loss functions observations y fitted values y_hat can optimized black-box function one-shot optimization. See, example, loss_rmse() loss_mae_with_observation_weight()—define ! alphas_grid data frame row represents parameter combination. Combinations evaluated can drawn uniformally using list_sampled_alphas():  course need use list_sampled_alphas() generate set parameter combinations evaluated. data frame columns alpha, alpha_seasonal, alpha_seasonal_decay required, can set parameters see fit. can useful re-use previously determined parameters, values close .","code":"alphas_grid <- list_sampled_alphas(   n_target = 1000L,   alpha_lower = 0,   alpha_upper = 1,   alpha_seasonal_lower = 0,   alpha_seasonal_upper = 1,   alpha_seasonal_decay_lower = 0,   alpha_seasonal_decay_upper = 1,   include_edge_cases = TRUE )  round(tail(alphas_grid), 4) #>       alpha alpha_seasonal alpha_seasonal_decay #> 995  0.3313         0.4698               1.0000 #> 996  0.7007         0.0188               0.3768 #> 997  0.8676         0.9452               0.5221 #> 998  0.8650         0.6694               0.0820 #> 999  0.6261         0.8915               0.5038 #> 1000 0.2067         0.3665               0.1281"},{"path":"http://timradtke.github.io/threedx/index.html","id":"id_3dx-interpolates-between-edge-cases","dir":"","previous_headings":"How It Works","what":"3DX Interpolates Between Edge Cases","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"Similarly simple exponential smoothing interpolates mean forecast naive forecast, 3DX interpolates 1) mean forecast, 2) naive forecast, 3) seasonal naive forecast, 4) seasonal mean forecast, 5) last period’s mean forecast. paramater combinations encode models can listed using list_edge_alphas(): choosing include_edge_cases = TRUE list_sampled_alphas(), first five returned parameter combinations edge cases. including , edge cases evaluated alongside parameter combinations learn_weights().","code":"list_edge_alphas() #>   alpha alpha_seasonal alpha_seasonal_decay #> 1     0              0                    0 #> 2     1              0                    0 #> 3     0              1                    1 #> 4     0              1                    0 #> 5     0              0                    1"},{"path":"http://timradtke.github.io/threedx/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Three-Dimensional Exponential Smoothing Forecasts","text":"Alexander Alexandrov, Konstantinos Benidis, Michael Bohlke-Schneider, Valentin Flunkert, Jan Gasthaus, Tim Januschowski, Danielle C. Maddix, Syama Rangapuram, David Salinas, Jasper Schulz, Lorenzo Stella, Ali Caner Türkmen, Yuyang Wang (2019). GluonTS: Probabilistic Time Series Models Python. https://arxiv.org/abs/1906.05264 James Bergstra, Yoshua Bengio (2012). Random Search Hyper-Parameter Optimization. https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf Jan Gasthaus (2016). Non-parametric time series forecaster. Technical report, Amazon, 2016. Rob J. Hyndman, Anne B. Koehler, Ralph D. Snyder, Simone Grose (2002). State Space Framework Automatic Forecasting using Exponential Smoothing Methods. https://doi.org/10.1016/S0169-2070(01)00110-8 Syama Sundar Rangapuram, Matthias W. Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang, Tim Januschowski (2018). Deep State Space Models Time Series Forecasting. https://papers.nips.cc/paper/2018/hash/5cf68969fb67aa6082363a6d4e6468e2-Abstract.html Suman Ravuri et al. (2021). Skilful precipitation nowcasting using deep generative models radar. https://www.nature.com/articles/s41586-021-03854-z Rafael de Rezende, Katharina Egert, Ignacio Marin, Guilherme Thompson (2021). White-boxed ISSM Approach Estimate Uncertainty Distributions Walmart Sales. https://arxiv.org/abs/2111.14721 Matthias Seeger, David Salinas, Valentin Flunkert (2016). Bayesian Intermittent Demand Forecasting Large Inventories. https://papers.nips.cc/paper/2016/hash/03255088ed63354a54e0e5ed957e9008-Abstract.html Matthias Seeger, Syama Rangapuram, Yuyang Wang, David Salinas, Jan Gasthaus, Tim Januschowski, Valentin Flunkert (2017). Approximate Bayesian Inference Linear State Space Models Intermittent Demand Forecasting Scale. https://arxiv.org/abs/1709.07638 P. R. Winters (1960). Forecasting Sales Exponentially Weighted Moving Averages. https://doi.org/10.1287/mnsc.6.3.324","code":""},{"path":"http://timradtke.github.io/threedx/reference/alphas_list_to_data_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"Cast a list of alphas as data frame — alphas_list_to_data_frame","title":"Cast a list of alphas as data frame — alphas_list_to_data_frame","text":"helper function casts list parameter tuples (used learn_weights()) named data frame. useful , example, plot parameters via ggplot2.","code":""},{"path":"http://timradtke.github.io/threedx/reference/alphas_list_to_data_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cast a list of alphas as data frame — alphas_list_to_data_frame","text":"","code":"alphas_list_to_data_frame(alphas_grid)"},{"path":"http://timradtke.github.io/threedx/reference/alphas_list_to_data_frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cast a list of alphas as data frame — alphas_list_to_data_frame","text":"alphas_grid list length 3 parameter tuples returned list_sampled_alphas() list_edge_alphas()","code":""},{"path":"http://timradtke.github.io/threedx/reference/alphas_list_to_data_frame.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cast a list of alphas as data frame — alphas_list_to_data_frame","text":"data frame three numeric columns called alpha, alpha_seasonal, alpha_seasonal_decay","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/autoplot.threedx.html","id":null,"dir":"Reference","previous_headings":"","what":"Autoplot method for threedx objects — autoplot.threedx","title":"Autoplot method for threedx objects — autoplot.threedx","text":"Use ggplot2 visualize fitted values weights fitted model class threedx","code":""},{"path":"http://timradtke.github.io/threedx/reference/autoplot.threedx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autoplot method for threedx objects — autoplot.threedx","text":"","code":"# S3 method for threedx autoplot(object, ..., date = NULL, show_params = TRUE)"},{"path":"http://timradtke.github.io/threedx/reference/autoplot.threedx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autoplot method for threedx objects — autoplot.threedx","text":"object Fitted model object class threedx returned learn_weights() ... ignored date Optional additional vector dates format can cast YYYY-MM-DD length object$y, used create x-axis show_params Logical; TRUE (default) fitted parameters displayed using ggplot2::facet_wrap()","code":""},{"path":"http://timradtke.github.io/threedx/reference/autoplot.threedx_paths.html","id":null,"dir":"Reference","previous_headings":"","what":"Autoplot method for threedx_paths objects — autoplot.threedx_paths","title":"Autoplot method for threedx_paths objects — autoplot.threedx_paths","text":"Use ggplot2 visualize marginal forecast quantiles, sample paths threedx forecast object class threedx_paths","code":""},{"path":"http://timradtke.github.io/threedx/reference/autoplot.threedx_paths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autoplot method for threedx_paths objects — autoplot.threedx_paths","text":"","code":"# S3 method for threedx_paths autoplot(   object,   ...,   method = c(\"forecast\", \"paths\")[1],   date = NULL,   date_future = NULL,   show_params = TRUE,   n = 5,   alpha = 0.75 )"},{"path":"http://timradtke.github.io/threedx/reference/autoplot.threedx_paths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autoplot method for threedx_paths objects — autoplot.threedx_paths","text":"object object class threedx_paths returned [predict.threedx()] ... ignored method One forecast visualization quantiles marginal forecast distribution (.e., usual fanchart), paths visualize sample paths joint forecast distribution date Optional additional vector dates format can cast YYYY-MM-DD length object$y, used create x-axis date_future Optional additional vector dates format can cast YYYY-MM-DD length object$y, used create x-axis forecast path show_params Logical; TRUE (default) fitted params displayed using ggplot2::facet_wrap() n Number paths add plot, small number recommended able see individual paths; positive scalar integer; used method \"paths\" alpha transparency parameter used adding paths plot, provided ggplot2::geom_point() ggplot2::geom_line(); used method \"paths\"","code":""},{"path":"http://timradtke.github.io/threedx/reference/autoplot.threedx_paths.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Autoplot method for threedx_paths objects — autoplot.threedx_paths","text":"Note: function use base::sample() randomly select paths added plot. Set seed require reproducibility.","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw innovations by bootstrapping from unweighted residual errors — draw_bootstrap","title":"Draw innovations by bootstrapping from unweighted residual errors — draw_bootstrap","text":"Draw innovations bootstrapping unweighted residual errors","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw innovations by bootstrapping from unweighted residual errors — draw_bootstrap","text":"","code":"draw_bootstrap(n, errors, ...)"},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw innovations by bootstrapping from unweighted residual errors — draw_bootstrap","text":"n number innovations draw errors residual errors used define distribution innovations drawn ... Additional arguments passed predict.threedx(), ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw innovations by bootstrapping from unweighted residual errors — draw_bootstrap","text":"vector type errors length n","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw innovations by bootstrapping from unweighted residual errors — draw_bootstrap","text":"","code":"model <- learn_weights(   y = rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(1:55 / 6))),   period_length = 12L,   alphas_grid = list_sampled_alphas(n_target = 25),   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 1000L,   observation_driven = FALSE,   innovation_function = draw_bootstrap )"},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_weighted.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw innovations by bootstrapping from weighted residual errors — draw_bootstrap_weighted","title":"Draw innovations by bootstrapping from weighted residual errors — draw_bootstrap_weighted","text":"Draw innovations bootstrapping weighted residual errors","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_weighted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw innovations by bootstrapping from weighted residual errors — draw_bootstrap_weighted","text":"","code":"draw_bootstrap_weighted(n, errors, weight_function, ...)"},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_weighted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw innovations by bootstrapping from weighted residual errors — draw_bootstrap_weighted","text":"n number innovations draw errors residual errors used define distribution innovations drawn weight_function function takes errors sole argument must return numeric vector length errors used prob argument underlying sample() call ... Additional arguments passed predict.threedx(), ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_weighted.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw innovations by bootstrapping from weighted residual errors — draw_bootstrap_weighted","text":"vector type errors length n","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_weighted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw innovations by bootstrapping from weighted residual errors — draw_bootstrap_weighted","text":"","code":"model <- learn_weights(   y = rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(1:55 / 6))),   period_length = 12L,   alphas_grid = list_sampled_alphas(n_target = 25),   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 1000L,   observation_driven = FALSE,   innovation_function = draw_bootstrap_weighted,   weight_function = function(x) {     weights_exponential(alpha = model$alpha, n = length(x))   } )"},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_zero_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw innovations by bootstrapping from unweighted zero-mean residual errors — draw_bootstrap_zero_mean","title":"Draw innovations by bootstrapping from unweighted zero-mean residual errors — draw_bootstrap_zero_mean","text":"Subtracts mean observed residuals forming bootstrap, thereby enforcing zero-mean samples expectation.","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_zero_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw innovations by bootstrapping from unweighted zero-mean residual errors — draw_bootstrap_zero_mean","text":"","code":"draw_bootstrap_zero_mean(n, errors, ...)"},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_zero_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw innovations by bootstrapping from unweighted zero-mean residual errors — draw_bootstrap_zero_mean","text":"n number innovations draw errors residual errors used define distribution innovations drawn ... Additional arguments passed predict.threedx(), ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_zero_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw innovations by bootstrapping from unweighted zero-mean residual errors — draw_bootstrap_zero_mean","text":"vector type errors length n","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/draw_bootstrap_zero_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw innovations by bootstrapping from unweighted zero-mean residual errors — draw_bootstrap_zero_mean","text":"","code":"model <- learn_weights(   y = rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(1:55 / 6))),   period_length = 12L,   alphas_grid = list_sampled_alphas(n_target = 25),   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 1000L,   observation_driven = FALSE,   innovation_function = draw_bootstrap_zero_mean )"},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_drift.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw i.i.d. innovations from a Normal distribution with non-zero mean — draw_normal_with_drift","title":"Draw i.i.d. innovations from a Normal distribution with non-zero mean — draw_normal_with_drift","text":"Draw ..d. innovations Normal distribution non-zero mean","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_drift.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw i.i.d. innovations from a Normal distribution with non-zero mean — draw_normal_with_drift","text":"","code":"draw_normal_with_drift(n, errors, ...)"},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_drift.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw i.i.d. innovations from a Normal distribution with non-zero mean — draw_normal_with_drift","text":"n number innovations draw errors residual errors used define distribution innovations drawn ... Additional arguments passed predict.threedx(), ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_drift.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw i.i.d. innovations from a Normal distribution with non-zero mean — draw_normal_with_drift","text":"vector type errors length n","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_drift.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw i.i.d. innovations from a Normal distribution with non-zero mean — draw_normal_with_drift","text":"","code":"model <- learn_weights(   y = 1:50,   period_length = 12L,   alphas_grid = list_sampled_alphas(n_target = 25),   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 1000L,   observation_driven = FALSE,   innovation_function = draw_normal_with_drift, )"},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_zero_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw i.i.d. innovations from a Normal distribution with zero mean — draw_normal_with_zero_mean","title":"Draw i.i.d. innovations from a Normal distribution with zero mean — draw_normal_with_zero_mean","text":"Draw ..d. innovations Normal distribution zero mean","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_zero_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw i.i.d. innovations from a Normal distribution with zero mean — draw_normal_with_zero_mean","text":"","code":"draw_normal_with_zero_mean(n, errors, ...)"},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_zero_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw i.i.d. innovations from a Normal distribution with zero mean — draw_normal_with_zero_mean","text":"n number innovations draw errors residual errors used define distribution innovations drawn ... Additional arguments passed predict.threedx(), ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_zero_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw i.i.d. innovations from a Normal distribution with zero mean — draw_normal_with_zero_mean","text":"vector type errors length n","code":""},{"path":"http://timradtke.github.io/threedx/reference/draw_normal_with_zero_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw i.i.d. innovations from a Normal distribution with zero mean — draw_normal_with_zero_mean","text":"","code":"model <- learn_weights(   y = 1:50,   period_length = 12L,   alphas_grid = list_sampled_alphas(n_target = 25),   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 1000L,   observation_driven = FALSE,   innovation_function = draw_normal_with_zero_mean, )"},{"path":"http://timradtke.github.io/threedx/reference/fitted.threedx.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract fitted values from a threedx model — fitted.threedx","title":"Extract fitted values from a threedx model — fitted.threedx","text":"Returns fitted one-step-ahead predictions training data threedx model. least first value missing.","code":""},{"path":"http://timradtke.github.io/threedx/reference/fitted.threedx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract fitted values from a threedx model — fitted.threedx","text":"","code":"# S3 method for threedx fitted(object, ...)"},{"path":"http://timradtke.github.io/threedx/reference/fitted.threedx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract fitted values from a threedx model — fitted.threedx","text":"object threedx model returned learn_weights() ... arguments passed fitted(), ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/fitted.threedx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract fitted values from a threedx model — fitted.threedx","text":"numeric vector length object$y","code":""},{"path":"http://timradtke.github.io/threedx/reference/k_largest_weights_sum_to_less_than_p_percent.html","id":null,"dir":"Reference","previous_headings":"","what":"Do the k largest weights sum up to less than p% of the total weights? — k_largest_weights_sum_to_less_than_p_percent","title":"Do the k largest weights sum up to less than p% of the total weights? — k_largest_weights_sum_to_less_than_p_percent","text":"Use function dynamically set observation_driven based fitted model's weights.","code":""},{"path":"http://timradtke.github.io/threedx/reference/k_largest_weights_sum_to_less_than_p_percent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Do the k largest weights sum up to less than p% of the total weights? — k_largest_weights_sum_to_less_than_p_percent","text":"","code":"k_largest_weights_sum_to_less_than_p_percent(weights, k, p)"},{"path":"http://timradtke.github.io/threedx/reference/k_largest_weights_sum_to_less_than_p_percent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Do the k largest weights sum up to less than p% of the total weights? — k_largest_weights_sum_to_less_than_p_percent","text":"weights vector weights sum 1, part model object returned learn_weights() k number weights consider, decreasing order size p threshold cumulative probability k weights might ","code":""},{"path":"http://timradtke.github.io/threedx/reference/k_largest_weights_sum_to_less_than_p_percent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Do the k largest weights sum up to less than p% of the total weights? — k_largest_weights_sum_to_less_than_p_percent","text":"logical length 1","code":""},{"path":"http://timradtke.github.io/threedx/reference/k_largest_weights_sum_to_less_than_p_percent.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Do the k largest weights sum up to less than p% of the total weights? — k_largest_weights_sum_to_less_than_p_percent","text":"useful judge whether trained threedx model's prediction combination least historical observations. using observation_driven prediction, prediction intervals collapse single point single historical observation (close ) 100% weights (happens, example, random walk seasonal naive models). cases can better switch observation_driven = FALSE get non-collapsed prediction interval based sampling residuals. k_largest_weights_sum_to_less_than_p_percent() can used make switch dynamically, based fitted weights. See also examples .","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/k_largest_weights_sum_to_less_than_p_percent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Do the k largest weights sum up to less than p% of the total weights? — k_largest_weights_sum_to_less_than_p_percent","text":"","code":"k_largest_weights_sum_to_less_than_p_percent(   weights = c(0.02, 0.05, 0.05, 0.04, 0.8, 0.03, 0.01),   k = 3,   p = 0.9 ) #> [1] TRUE  k_largest_weights_sum_to_less_than_p_percent(   weights = c(0.02, 0.05, 0.05, 0.04, 0.8, 0.03, 0.01),   k = 4,   p = 0.9 ) #> [1] FALSE  # Now apply it dynamically during prediction to set `observation_driven`  set.seed(9284) y <- stats::rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi((5 + 1:55 )/ 6)))  model <- learn_weights(   y = y,   alphas_grid = list_sampled_alphas(     n_target = 1000L,     include_edge_cases = TRUE   ),   period_length = 12L,   loss_function = loss_mae )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 2500L,   innovation_function = draw_normal_with_zero_mean,   observation_driven = k_largest_weights_sum_to_less_than_p_percent(     weights = model$weights,     k = 4,     p = 0.95   ) )  print(forecast$observation_driven) #> [1] TRUE"},{"path":"http://timradtke.github.io/threedx/reference/learn_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a 3DX model to a time series — learn_weights","title":"Fit a 3DX model to a time series — learn_weights","text":"Returns threedx model applied time series y learning optimal set parameters minimizing provided loss function. Use predict.threedx() generate forecast based fitted model.","code":""},{"path":"http://timradtke.github.io/threedx/reference/learn_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a 3DX model to a time series — learn_weights","text":"","code":"learn_weights(   y,   period_length,   alphas_grid,   loss_function,   penalize = FALSE,   loss_increase = 1 )"},{"path":"http://timradtke.github.io/threedx/reference/learn_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a 3DX model to a time series — learn_weights","text":"y time series forecasted numeric vector (ts() object) period_length presumed length y's seasonal period; example, 12L monthly observations, 7L daily observations, ... alphas_grid data frame possible parameter combinations generate weights final model. optimal parameter set chosen based minimization loss_function. expected columns numeric called alpha, alpha_seasonal, alpha_seasonal_decay. least one row must provided. values must 0 1. Use, example, list_sampled_alphas() list_edge_alphas() generate data frame, generate way like. loss_function function first argument y_hat optionally arguments. Usually, compute loss, least additional y argument required compute errors. Must able handle additional parameters via ... allow potential future changes set arguments passed loss_function learn_weights(). examples, see loss_mae() loss_mae_with_observation_weight(). can assumed arguments y_hat y passed learn_weights() numeric vectors equal length. provided loss_function must return numeric scalar value. penalize Logical, FALSE default. TRUE, try pick set parameters simpler increasing loss much. allowed increase loss percentage points defined via loss_increase. model simpler parameters equal exactly zero one, correspond edge cases. loss_increase non-negative scalar value loss may increased compared best possible loss, percentage points. argument ignored unless penalize = TRUE. default 1 corresponds range 1 percentage point increase loss.","code":""},{"path":"http://timradtke.github.io/threedx/reference/learn_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a 3DX model to a time series — learn_weights","text":"fitted model object class threedx, list : numeric vector weights length input y, assigning weight index past observations. weights sum 1. weights fitted weights used produce forecasts. numeric scalar alpha, optimal paramater exponential smoothing component chosen model training numeric scalar alpha_seasonal, optimal paramater seasonal exponential smoothing component chosen model training numeric scalar alpha_seasonal_decay, optimal paramater seasonal exponential decay smoothing component chosen model training numeric vector fitted containing fitted values index y; period_length-first observations may missing. numeric vector residuals containing residuals training data computed y - fitted, thus period_length-first observations may missing. numeric vector y, input y scalar n, number observations provided via y scalar period_length, input period_length function loss_function, provided loss_function scalar loss, value computed provided loss_function based input y fitted values (ignoring initial missing values) loss minimizing set parameters reported alpha, alpha_seasonal, alpha_seasonal_decay logical penalize, identical provided function argument scalar loss_increase, identical provided function argument list full containing intermediate results observed model optimization parameter combinations provided via alphas_grid","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/learn_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a 3DX model to a time series — learn_weights","text":"","code":"set.seed(9284) y <- stats::rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi((5 + 1:55 )/ 6)))  alphas_grid <- list_sampled_alphas(   n_target = 1000L,   include_edge_cases = TRUE )  model <- learn_weights(   y = y,   alphas_grid = alphas_grid,   period_length = 12L,   loss_function = loss_mae )  if (require(\"ggplot2\")) {   autoplot(model) } #> Loading required package: ggplot2   model_penalized <- learn_weights(   y = y,   alphas_grid = alphas_grid,   period_length = 12L,   loss_function = loss_mae,   penalize = TRUE,   loss_increase = 10 )  model$full$best_alphas #>        alpha alpha_seasonal alpha_seasonal_decay #> 1 0.03240655      0.8265107             0.173151 model_penalized$full$best_alphas #>   alpha alpha_seasonal alpha_seasonal_decay #> 1     0      0.9146342                    0  if (require(\"ggplot2\")) {   autoplot(model_penalized) }"},{"path":"http://timradtke.github.io/threedx/reference/list_edge_alphas.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a data frame of possible alpha values to evaluate during training — list_edge_alphas","title":"Generate a data frame of possible alpha values to evaluate during training — list_edge_alphas","text":"parameter combinations generated list_edge_alphas() encode set important edge cases threedx model can interpolate.","code":""},{"path":"http://timradtke.github.io/threedx/reference/list_edge_alphas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a data frame of possible alpha values to evaluate during training — list_edge_alphas","text":"","code":"list_edge_alphas()"},{"path":"http://timradtke.github.io/threedx/reference/list_edge_alphas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a data frame of possible alpha values to evaluate during training — list_edge_alphas","text":"data frame columns alpha, alpha_seasonal, alpha_seasonal_decay, five rows; values 0 1","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/list_edge_alphas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a data frame of possible alpha values to evaluate during training — list_edge_alphas","text":"","code":"list_edge_alphas() #>   alpha alpha_seasonal alpha_seasonal_decay #> 1     0              0                    0 #> 2     1              0                    0 #> 3     0              1                    1 #> 4     0              1                    0 #> 5     0              0                    1"},{"path":"http://timradtke.github.io/threedx/reference/list_sampled_alphas.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a data frame of possible alpha values to evaluate during training — list_sampled_alphas","title":"Generate a data frame of possible alpha values to evaluate during training — list_sampled_alphas","text":"Generate data frame possible alpha values evaluate training","code":""},{"path":"http://timradtke.github.io/threedx/reference/list_sampled_alphas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a data frame of possible alpha values to evaluate during training — list_sampled_alphas","text":"","code":"list_sampled_alphas(   n_target = 100,   alpha_lower = 0,   alpha_upper = 1,   alpha_seasonal_lower = 0,   alpha_seasonal_upper = 1,   alpha_seasonal_decay_lower = 0,   alpha_seasonal_decay_upper = 1,   oversample_lower = 0.05,   oversample_upper = 0.05,   include_edge_cases = FALSE,   seed = NULL )"},{"path":"http://timradtke.github.io/threedx/reference/list_sampled_alphas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a data frame of possible alpha values to evaluate during training — list_sampled_alphas","text":"n_target targeted number 3-parameter tuples; since tuples generated one-time shot sampling (instead , e.g., rejection sampling) distinct samples returned, realized length list tuples may shorter n_target. Especially oversample_lower /oversample_upper large compared allowed parameter range, realized length resulting list can shorter n_target many tuples become {0,1}-valued. alpha_lower numeric scalar 0,1 serving lower bound applied alpha parameter returned tuples alpha_upper numeric scalar 0,1 serving upper bound applied alpha parameter returned tuples; must least large alpha_lower. equal alpha_lower, samples alpha equal alpha_lower equal alpha_upper (allowed value). alpha_seasonal_lower numeric scalar 0,1 serving lower bound applied alpha_seasonal parameter returned tuples alpha_seasonal_upper numeric scalar 0,1 serving upper bound applied alpha_seasonal parameter returned tuples; must least large alpha_seasonal_lower. equal alpha_seasonal_lower, samples alpha_seasonal equal alpha_seasonal_lower equal alpha_seasonal_upper (allowed value). alpha_seasonal_decay_lower numeric scalar 0,1 serving lower bound applied alpha_seasonal_decay parameter returned tuples alpha_seasonal_decay_upper numeric scalar 0,1 serving upper bound applied alpha_seasonal_decay parameter returned tuples; must least large alpha_seasonal_decay_lower. equal alpha_seasonal_decay_lower, samples alpha_seasonal_decay equal alpha_seasonal_decay_lower equal alpha_seasonal_decay_upper (allowed value). oversample_lower non-negative numeric scalar adding additional weight parameters' lower bounds sampling. Since sampling generally draws values continuous range, border cases exact lower upper bound (especially 0 1) never drawn even though represent often well performing special cases. specifying oversample_lower, explicit probability assigned lower bound value. Extends lower bounds alpha_lower, alpha_seasonal_lower, alpha_seasonal_decay_lower alpha_lower - oversample_lower etc. sampling parameters via runif(min = alpha_lower - oversample_lower, ...) etc. sampling, parameter values thresholded back alpha_lower etc. default case lower bounds equal 0 upper bounds equal 1, choice oversample_lower = 0.05 creates roughly 5% probability returning exactly lower bound value 0 parameter value. oversample_upper non-negative numeric scalar adding additional weight parameters' upper bounds sampling. Since sampling generally draws values continuous range, border cases exact lower upper bound (especially 0 1) never drawn even though represent often well performing special cases. specifying oversample_upper, explicit probability assigned upper bound value. Extends upper bounds alpha_upper, alpha_seasonal_upper, alpha_seasonal_decay_upper alpha_upper + oversample_upper etc. sampling parameters via runif(max = alpha_upper + oversample_upper, ...) etc. sampling, parameter values thresholded back alpha_upper etc. default case lower bounds equal 0 upper bounds equal 1, choice oversample_lower = 0.05 creates roughly 5% probability returning exactly lower bound value 1 parameter value. include_edge_cases Logical; TRUE, hardcoded set tuples representing special cases model specifications included. Since take currently five entries list, useful n_target least length five. Otherwise returned list contain (subset ) special cases. achieve , list_edge_alphas() preferred method. Including special cases lead comparison sampled parameters benchmarks mean forecast, random walk forecast, seasonal naive forecast. seed random seed used sampling parameters. reset .Random.seed value function call upon exit.","code":""},{"path":"http://timradtke.github.io/threedx/reference/list_sampled_alphas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a data frame of possible alpha values to evaluate during training — list_sampled_alphas","text":"data frame columns alpha, alpha_seasonal, alpha_seasonal_decay n_target rows; values 0 1","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/list_sampled_alphas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a data frame of possible alpha values to evaluate during training — list_sampled_alphas","text":"","code":"alphas_grid <- list_sampled_alphas(n_target = 1000L)  if (require(\"ggplot2\")) { ggplot2::ggplot(   alphas_grid,   ggplot2::aes(x = alpha, y = alpha_seasonal, fill = alpha_seasonal_decay) ) +   ggplot2::geom_point(pch = 21, color = \"white\") +   ggplot2::scale_fill_gradient2(midpoint = 0.5) +   ggplot2::labs(title = \"Sampled Grid of Parameters to Evaluate\") }"},{"path":"http://timradtke.github.io/threedx/reference/loss_mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean absolute error loss function — loss_mae","title":"Mean absolute error loss function — loss_mae","text":"Mean absolute error loss function","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean absolute error loss function — loss_mae","text":"","code":"loss_mae(y_hat, y, ...)"},{"path":"http://timradtke.github.io/threedx/reference/loss_mae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean absolute error loss function — loss_mae","text":"y_hat numeric vector representing predictions y numeric vector representing observations ... Additional arguments passed functions; ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean absolute error loss function — loss_mae","text":"scalar value","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_ignoring_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean absolute error loss function ignoring bias — loss_mae_ignoring_bias","title":"Mean absolute error loss function ignoring bias — loss_mae_ignoring_bias","text":"Subtracts median observed residuals computing mean absolute error. can helpful predicting time series bias due trend component expected can captured innovation function choice.","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_ignoring_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean absolute error loss function ignoring bias — loss_mae_ignoring_bias","text":"","code":"loss_mae_ignoring_bias(y_hat, y, ...)"},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_ignoring_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean absolute error loss function ignoring bias — loss_mae_ignoring_bias","text":"y_hat numeric vector representing predictions y numeric vector representing observations ... Additional arguments passed functions; ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_ignoring_bias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean absolute error loss function ignoring bias — loss_mae_ignoring_bias","text":"scalar value","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_with_observation_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Observation-weighted mean absolute error loss function — loss_mae_with_observation_weight","title":"Observation-weighted mean absolute error loss function — loss_mae_with_observation_weight","text":"Observation-weighted mean absolute error loss function","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_with_observation_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Observation-weighted mean absolute error loss function — loss_mae_with_observation_weight","text":"","code":"loss_mae_with_observation_weight(y_hat, y, ...)"},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_with_observation_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Observation-weighted mean absolute error loss function — loss_mae_with_observation_weight","text":"y_hat numeric vector representing predictions y numeric vector representing observations ... Additional arguments passed functions; ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_with_observation_weight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Observation-weighted mean absolute error loss function — loss_mae_with_observation_weight","text":"scalar value","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_mae_with_observation_weight.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Observation-weighted mean absolute error loss function — loss_mae_with_observation_weight","text":"Suman Ravuri et al. (2021). Skilful precipitation nowcasting using deep generative models radar. https://www.nature.com/articles/s41586-021-03854-z","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"Root-mean-square error loss function — loss_rmse","title":"Root-mean-square error loss function — loss_rmse","text":"Root-mean-square error loss function","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Root-mean-square error loss function — loss_rmse","text":"","code":"loss_rmse(y_hat, y, ...)"},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Root-mean-square error loss function — loss_rmse","text":"y_hat numeric vector representing predictions y numeric vector representing observations ... Additional arguments passed functions; ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Root-mean-square error loss function — loss_rmse","text":"scalar value","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse_ignoring_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Root-mean-square error loss function ignoring bias — loss_rmse_ignoring_bias","title":"Root-mean-square error loss function ignoring bias — loss_rmse_ignoring_bias","text":"Subtracts mean observed residuals computing root-mean-square error. can helpful predicting time series bias due trend component expected can captured innovation function choice.","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse_ignoring_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Root-mean-square error loss function ignoring bias — loss_rmse_ignoring_bias","text":"","code":"loss_rmse_ignoring_bias(y_hat, y, ...)"},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse_ignoring_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Root-mean-square error loss function ignoring bias — loss_rmse_ignoring_bias","text":"y_hat numeric vector representing predictions y numeric vector representing observations ... Additional arguments passed functions; ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/loss_rmse_ignoring_bias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Root-mean-square error loss function ignoring bias — loss_rmse_ignoring_bias","text":"scalar value","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/plot_fitted.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot fitted values of an threedx model — plot_fitted","title":"Plot fitted values of an threedx model — plot_fitted","text":"function requires ggplot2. Whether namespace available checked function run. ggplot2 suggested, default import.","code":""},{"path":"http://timradtke.github.io/threedx/reference/plot_fitted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot fitted values of an threedx model — plot_fitted","text":"","code":"plot_fitted(object, date = NULL, show_params = TRUE)"},{"path":"http://timradtke.github.io/threedx/reference/plot_fitted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot fitted values of an threedx model — plot_fitted","text":"object Fitted model object returned learn_weights() date Optional additional vector dates format can cast YYYY-MM-DD length object$y, used create x-axis show_params Logical; TRUE (default) fitted parameters displayed using ggplot2::facet_wrap()","code":""},{"path":"http://timradtke.github.io/threedx/reference/plot_fitted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot fitted values of an threedx model — plot_fitted","text":"","code":"set.seed(4278) y <- rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(1:55 / 6)))  model <- learn_weights(   y = y,   alphas_grid = list_sampled_alphas(n_target = 50L),   period_length = 12L,   loss_function = loss_mae ) threedx:::plot_fitted(object = model)"},{"path":"http://timradtke.github.io/threedx/reference/plot_forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the marginal quantile forecast of a threedx model — plot_forecast","title":"Plot the marginal quantile forecast of a threedx model — plot_forecast","text":"function requires ggplot2. Whether namespace available checked function run. ggplot2 suggested, default import.","code":""},{"path":"http://timradtke.github.io/threedx/reference/plot_forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the marginal quantile forecast of a threedx model — plot_forecast","text":"","code":"plot_forecast(object, date = NULL, date_future = NULL, show_params = TRUE)"},{"path":"http://timradtke.github.io/threedx/reference/plot_forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the marginal quantile forecast of a threedx model — plot_forecast","text":"object object class threedx_paths returned predict.threedx() date Optional additional vector dates format can cast YYYY-MM-DD length object$y, used create x-axis date_future Optional additional vector dates format can cast YYYY-MM-DD length object$y, used create x-axis forecast paths show_params Logical; TRUE (default) fitted params displayed using ggplot2::facet_wrap()","code":""},{"path":"http://timradtke.github.io/threedx/reference/plot_forecast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the marginal quantile forecast of a threedx model — plot_forecast","text":"","code":"set.seed(4278) y <- rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(1:55 / 6)))  model <- learn_weights(   y = y,   alphas_grid = list_sampled_alphas(n_target = 50L),   period_length = 12L,   loss_function = loss_mae )  paths <- predict(   object = model,   horizon = 12,   n_samples = 2500L,   observation_driven = TRUE )  threedx:::plot_forecast(object = paths)"},{"path":"http://timradtke.github.io/threedx/reference/plot_paths.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a few forecast sample paths of a threedx model — plot_paths","title":"Plot a few forecast sample paths of a threedx model — plot_paths","text":"function requires ggplot2. Whether namespace available checked function run. ggplot2 suggested, default import.","code":""},{"path":"http://timradtke.github.io/threedx/reference/plot_paths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a few forecast sample paths of a threedx model — plot_paths","text":"","code":"plot_paths(   object,   date = NULL,   date_future = NULL,   n = 5,   alpha = 0.75,   show_params = TRUE )"},{"path":"http://timradtke.github.io/threedx/reference/plot_paths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a few forecast sample paths of a threedx model — plot_paths","text":"object object class threedx_paths returned predict.threedx() date Optional additional vector dates format can cast YYYY-MM-DD, used create x-axis date_future Optional additional vector dates format can cast YYYY-MM-DD, used create x-axis forecast paths n Number paths add plot, small number recommended able see individual paths; positive scalar integer alpha transparency parameter used adding paths plot, provided ggplot2::geom_point() ggplot2::geom_line() show_params Logical; TRUE (default) fitted params displayed using ggplot2::facet_wrap()","code":""},{"path":"http://timradtke.github.io/threedx/reference/plot_paths.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a few forecast sample paths of a threedx model — plot_paths","text":"Note: function use base::sample() randomly select paths added plot. Set seed require reproducibility.","code":""},{"path":"http://timradtke.github.io/threedx/reference/plot_paths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a few forecast sample paths of a threedx model — plot_paths","text":"","code":"set.seed(4278) y <- rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi(1:55 / 6)))  model <- learn_weights(   y = y,   alphas_grid = list_sampled_alphas(n_target = 50L),   period_length = 12L,   loss_function = loss_mae )  paths <- predict(   object = model,   horizon = 12,   n_samples = 2500L,   observation_driven = TRUE )  threedx:::plot_paths(object = paths, n = 3)"},{"path":"http://timradtke.github.io/threedx/reference/predict.threedx.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw forecast sample paths from a fitted 3DX model — predict.threedx","title":"Draw forecast sample paths from a fitted 3DX model — predict.threedx","text":"Draw forecast sample paths fitted 3DX model","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict.threedx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw forecast sample paths from a fitted 3DX model — predict.threedx","text":"","code":"# S3 method for threedx predict(   object,   horizon,   n_samples,   observation_driven,   innovation_function,   postprocess = identity,   ... )"},{"path":"http://timradtke.github.io/threedx/reference/predict.threedx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw forecast sample paths from a fitted 3DX model — predict.threedx","text":"object fitted model object class threedx horizon integer defining forecast horizon n_samples integer defining number sample paths draw observation_driven Logical; TRUE, sample paths generated drawing weighted historical observations directly instead adding innovation noise current mean forecast. similar Non-Parametric Time Series forecaster (NPTS) described \"GluonTS: Probabilistic Time Series Models Python\" (2019) Alexandrov et al. (see https://arxiv.org/abs/1906.05264). FALSE, sample paths generated adding innovation noise top current weighted average forecast. innovation_function function arguments n errors. Must able handle additional parameters via ... allow potential future changes set arguments passed innovation_function predict.threedx(). examples, see draw_normal_with_drift() draw_bootstrap_weighted(). provided innovation_function must return numeric vector length n contains ..d samples can used sample path forecast horizon. argument ignored observation_driven=TRUE. postprocess function applied numeric vector drawn samples single step-ahead samples used update state model, outliers removed (applicable). default equal identity(), also something like function(x) pmax(x, 0) enforce lower bound 0, transformation interest returns numeric vector equal length input. Note can cause arbitrary errors caused author function provided postprocess. examples, see to_non_negative_with_identical_mean() to_moment_matched_nbinom(). ... Additional arguments passed innovation_function","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict.threedx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw forecast sample paths from a fitted 3DX model — predict.threedx","text":"forecast object class threedx_paths, list : paths numeric matrix dimensions n_samples-times-horizon. matrix stores forecast sample paths probabilistic forecast returned threedx model. Aggregate across first dimension derive expectations forecast distribution, aggregate across second dimension derive sums forecast horizon. input horizon argument input n_samples argument input observation_driven argument model model provided via object, object class threedx","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict.threedx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw forecast sample paths from a fitted 3DX model — predict.threedx","text":"observation_driven can effective forecasting wide ranges time series, induced forecast distribution collapses single point alpha, alpha_seasonal, alpha_seasonal_decay values tend towards 1. corresponding point prediction may still optimal, uncertainty forecast likely underestimated. example, alpha = 0.98, alpha_seasonal=0, alpha_seasonal_decay=0, resulting forecast distribution assigns 98% probability recent observation, thus collapsing prediction intervals onto point. can highly unrealistic time series whose level changing rapidly therefore require large alpha values. circumvent issue, one can design certain conditions observation_driven set TRUE. example, using k_largest_weights_sum_to_less_than_p_percent(), one can check learned model assigns weight least observations, set observation_driven=TRUE. However, underlying time series truly random walk, observation_driven=TRUE always poor choice limits range possible future values much.","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/predict.threedx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw forecast sample paths from a fitted 3DX model — predict.threedx","text":"","code":"set.seed(9284) y <- stats::rpois(n = 55, lambda = pmax(0.1, 1 + 10 * sinpi((5 + 1:55 )/ 6)))  model <- learn_weights(   y = y,   alphas_grid = list_sampled_alphas(     n_target = 1000L,     include_edge_cases = TRUE   ),   period_length = 12L,   loss_function = loss_mae )  forecast_observation_driven <- predict(   object = model,   horizon = 12L,   n_samples = 2500L,   observation_driven = TRUE )  if (require(\"ggplot2\")) {   autoplot(forecast_observation_driven) }   forecast_latent <- predict(   object = model,   horizon = 12L,   n_samples = 2500L,   observation_driven = FALSE,   innovation_function = draw_bootstrap )  if (require(\"ggplot2\")) {   autoplot(forecast_latent) }   forecast_latent_with_postprocessing <- predict(   object = model,   horizon = 12L,   n_samples = 2500L,   observation_driven = FALSE,   innovation_function = draw_normal_with_zero_mean,   postprocess = function(x) round(pmax(x, 0)) )  if (require(\"ggplot2\")) {   autoplot(forecast_latent_with_postprocessing) }"},{"path":"http://timradtke.github.io/threedx/reference/predict_one_step_ahead_with_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict one-step ahead for each of the alpha specifications — predict_one_step_ahead_with_grid","title":"Predict one-step ahead for each of the alpha specifications — predict_one_step_ahead_with_grid","text":"Generates matrix weights column contains weights one possible paramater values evaluated training. derives one-step-ahead predictions set weights matrix multiplication time series vector.","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict_one_step_ahead_with_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict one-step ahead for each of the alpha specifications — predict_one_step_ahead_with_grid","text":"","code":"predict_one_step_ahead_with_grid(y, alphas_grid, n, period_length)"},{"path":"http://timradtke.github.io/threedx/reference/predict_one_step_ahead_with_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict one-step ahead for each of the alpha specifications — predict_one_step_ahead_with_grid","text":"y time series vector length n alphas_grid data frame possible parameter combinations n number observations time series period_length length seasonal period","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict_one_step_ahead_with_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict one-step ahead for each of the alpha specifications — predict_one_step_ahead_with_grid","text":"numeric vector length nrow(alphas_grid)","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict_with_observations.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate sample paths using observed values — predict_with_observations","title":"Generate sample paths using observed values — predict_with_observations","text":"Generate sample paths using observed values","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict_with_observations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate sample paths using observed values — predict_with_observations","text":"","code":"predict_with_observations(y_m, object, horizon, n_samples, postprocess)"},{"path":"http://timradtke.github.io/threedx/reference/predict_with_state.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate sample paths using latent state — predict_with_state","title":"Generate sample paths using latent state — predict_with_state","text":"Generate sample paths using latent state","code":""},{"path":"http://timradtke.github.io/threedx/reference/predict_with_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate sample paths using latent state — predict_with_state","text":"","code":"predict_with_state(   y_m,   object,   horizon,   n_samples,   innovation_function,   postprocess,   ... )"},{"path":"http://timradtke.github.io/threedx/reference/residuals.threedx.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract residuals from a threedx model — residuals.threedx","title":"Extract residuals from a threedx model — residuals.threedx","text":"Returns residuals one-step-ahead predictions training data threedx model. least first value missing.","code":""},{"path":"http://timradtke.github.io/threedx/reference/residuals.threedx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract residuals from a threedx model — residuals.threedx","text":"","code":"# S3 method for threedx residuals(object, ...)"},{"path":"http://timradtke.github.io/threedx/reference/residuals.threedx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract residuals from a threedx model — residuals.threedx","text":"object threedx model returned learn_weights() ... arguments passed residuals(), ignored","code":""},{"path":"http://timradtke.github.io/threedx/reference/residuals.threedx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract residuals from a threedx model — residuals.threedx","text":"numeric vector length object$y","code":""},{"path":"http://timradtke.github.io/threedx/reference/threedx-package.html","id":null,"dir":"Reference","previous_headings":"","what":"threedx: Three-Dimensional Exponential Smoothing Forecasts — threedx-package","title":"threedx: Three-Dimensional Exponential Smoothing Forecasts — threedx-package","text":"Use 3DX generate interpretable probabilistic forecasts purely weighting values observed time series. Unique 3DX can used derive forecasts based “latent state” also observation-driven, drawing future realizations purely observed values. can effective count intermittent series. 3DX sampling distribution combination three components: first weighs observations exponentially, second weighs observations within seasonal period exponentially, third weighs seasonal periods time exponentially.","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/threedx-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"threedx: Three-Dimensional Exponential Smoothing Forecasts — threedx-package","text":"Maintainer: Tim Radtke tim@timradtke.net","code":""},{"path":"http://timradtke.github.io/threedx/reference/to_moment_matched_nbinom.html","id":null,"dir":"Reference","previous_headings":"","what":"Postprocess to samples from a moment-matched negative-binomial distribution — to_moment_matched_nbinom","title":"Postprocess to samples from a moment-matched negative-binomial distribution — to_moment_matched_nbinom","text":"Use function postprocess samples forecast distribution samples negative binomial distribution fitted moment-matching (using mean variance) input samples x. useful convert samples generated via different innovation_function like [draw_normal_with_zero_mean()] [draw_bootstrap()] count distribution.","code":""},{"path":"http://timradtke.github.io/threedx/reference/to_moment_matched_nbinom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Postprocess to samples from a moment-matched negative-binomial distribution — to_moment_matched_nbinom","text":"","code":"to_moment_matched_nbinom(x)"},{"path":"http://timradtke.github.io/threedx/reference/to_moment_matched_nbinom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Postprocess to samples from a moment-matched negative-binomial distribution — to_moment_matched_nbinom","text":"x Numeric vector non-negative samples least length 2","code":""},{"path":"http://timradtke.github.io/threedx/reference/to_moment_matched_nbinom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Postprocess to samples from a moment-matched negative-binomial distribution — to_moment_matched_nbinom","text":"Numeric vector length equal x","code":""},{"path":"http://timradtke.github.io/threedx/reference/to_moment_matched_nbinom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Postprocess to samples from a moment-matched negative-binomial distribution — to_moment_matched_nbinom","text":"required forecast output count data (forecasting demand products), can better using round() similar preserve features forecast distribution.","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/to_moment_matched_nbinom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Postprocess to samples from a moment-matched negative-binomial distribution — to_moment_matched_nbinom","text":"","code":"x <- to_non_negative_with_identical_mean(   stats::rnorm(n = 10000, mean = 5, sd = 3) ) y <- to_moment_matched_nbinom(x = x) summary(x); stats::var(x) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   0.000   2.953   4.911   4.974   6.853  17.089  #> [1] 7.94514 summary(y); stats::var(y) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   0.000   3.000   5.000   4.928   7.000  19.000  #> [1] 7.82657  # Forecasting simple count data  set.seed(992) y <- stats::rnbinom(n = 50, mu = 3, size = 3/2) model <- learn_weights(   y = y,   alphas_grid = list_sampled_alphas(     n_target = 1000L,     include_edge_cases = TRUE   ),   period_length = 12L,   loss_function = loss_rmse )  forecast <- predict(   object = model,   horizon = 12L,   n_samples = 2501L,   observation_driven = FALSE,   innovation_function = draw_normal_with_zero_mean,   postprocess = to_moment_matched_nbinom )  forecast$paths[1:5, ] #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] #> [1,]    1    1    5    1    4    3    1    1    0     0     2     2 #> [2,]    4    1    0    2    3    2    2    2    5     6     1     0 #> [3,]    8    3    0    6    1    2    0    5    1     2     2     0 #> [4,]    2    0    6    4    7    1    0    4    3     6     4     0 #> [5,]    1    1    6    3    1    7    5    2    4     4     5     2  if (require(\"ggplot2\")) {   autoplot(forecast)   autoplot(forecast, method = \"paths\") }"},{"path":"http://timradtke.github.io/threedx/reference/to_non_negative_with_identical_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn values non-negative while preserving their sample mean — to_non_negative_with_identical_mean","title":"Turn values non-negative while preserving their sample mean — to_non_negative_with_identical_mean","text":"Postprocess function turning forecast samples non-negative keeping mean value scaling samples (unless sample mean originally negative).","code":""},{"path":"http://timradtke.github.io/threedx/reference/to_non_negative_with_identical_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn values non-negative while preserving their sample mean — to_non_negative_with_identical_mean","text":"","code":"to_non_negative_with_identical_mean(x)"},{"path":"http://timradtke.github.io/threedx/reference/to_non_negative_with_identical_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn values non-negative while preserving their sample mean — to_non_negative_with_identical_mean","text":"x numeric vector","code":""},{"path":"http://timradtke.github.io/threedx/reference/to_non_negative_with_identical_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn values non-negative while preserving their sample mean — to_non_negative_with_identical_mean","text":"Numeric vector length equal x","code":""},{"path":"http://timradtke.github.io/threedx/reference/to_non_negative_with_identical_mean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Turn values non-negative while preserving their sample mean — to_non_negative_with_identical_mean","text":"identical sample mean can enforced, generally decrease sample variance way maintain mean turning negative samples zero enforce non-negativity constraint. returned samples always non-negative. sample mean identical achieved given non-negative samples.","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/to_non_negative_with_identical_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Turn values non-negative while preserving their sample mean — to_non_negative_with_identical_mean","text":"","code":"to_non_negative_with_identical_mean(x = c(-1, 0, 1, 2)) #> [1] 0.0000000 0.0000000 0.6666667 1.3333333  x <- rnorm(100, 0.5) summary(x) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> -1.8913 -0.1308  0.5679  0.4928  1.1706  3.0221  summary(to_non_negative_with_identical_mean(x)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.0000  0.0000  0.3899  0.4928  0.8036  2.0745   x <- rnorm(100, -1) summary(x) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> -4.0423 -1.8373 -1.1560 -1.1432 -0.3465  0.9701  # can't keep identical mean as original mean is negative summary(to_non_negative_with_identical_mean(x)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00000 0.00000 0.00000 0.06034 0.00000 0.97015"},{"path":"http://timradtke.github.io/threedx/reference/trade_loss_for_simplicity.html","id":null,"dir":"Reference","previous_headings":"","what":"Allow for an increase in loss to find a simpler model — trade_loss_for_simplicity","title":"Allow for an increase in loss to find a simpler model — trade_loss_for_simplicity","text":"Allow increase loss find simpler model","code":""},{"path":"http://timradtke.github.io/threedx/reference/trade_loss_for_simplicity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allow for an increase in loss to find a simpler model — trade_loss_for_simplicity","text":"","code":"trade_loss_for_simplicity(alphas_grid, losses, increase)"},{"path":"http://timradtke.github.io/threedx/reference/trade_loss_for_simplicity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allow for an increase in loss to find a simpler model — trade_loss_for_simplicity","text":"alphas_grid data frame model parameters evaluated losses vector length equal rows alphas_grid, representing loss associated set model parameters increase allowed increase loss percentage points compared best observed loss","code":""},{"path":"http://timradtke.github.io/threedx/reference/trade_loss_for_simplicity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Allow for an increase in loss to find a simpler model — trade_loss_for_simplicity","text":"scalar integer","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/trade_loss_for_simplicity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Allow for an increase in loss to find a simpler model — trade_loss_for_simplicity","text":"","code":"# Returns `1` when all options are equal  alphas_grid <- data.frame(   alpha = rep(0, 10),   alpha_seasonal = rep(0, 10),   alpha_seasonal_decay = rep(0, 10) )  losses <- rep(1, 10)  trade_loss_for_simplicity(   alphas_grid = alphas_grid,   losses = losses,   increase = 1 ) #> [1] 1  # Considers only options with 0 loss if best loss is 0 # (here, the originally best index with 0 loss has a less simple model)  alphas_grid <- data.frame(   alpha = c(0.5, rep(0, 2)),   alpha_seasonal = rep(0, 3),   alpha_seasonal_decay = rep(0, 3) )  losses <- c(0, 1, 0)  trade_loss_for_simplicity(   alphas_grid = alphas_grid,   losses = losses,   increase = 1 ) #> [1] 3  # When multiple options exist in the allowed range of performance reduction, # the best loss of those with the highest simplicity dominates  alphas_grid <- data.frame(   alpha = c(0.5, 0.5, 0.5, 0.5, 0),   alpha_seasonal = c(0.5, 0.5, 0, 0, 0),   alpha_seasonal_decay = c(0.5, 0, 0, 0, 0) )  losses <- c(100, 101, 103, 102, 110)  trade_loss_for_simplicity(   alphas_grid = alphas_grid,   losses = losses,   increase = 5 ) #> [1] 4"},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive exponential weights — weights_exponential","title":"Derive exponential weights — weights_exponential","text":"larger value alpha assign larger weights recent observations.","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive exponential weights — weights_exponential","text":"","code":"weights_exponential(alpha, n)"},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive exponential weights — weights_exponential","text":"alpha value 0 1 determines quick exponential decay weights n number weights create; usually equal number observations time series","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive exponential weights — weights_exponential","text":"monotonically increasing numeric vector n values 0 1 sum 1","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive exponential weights — weights_exponential","text":"","code":"weights_exponential(alpha = 0.25, n = 5) #> [1] 0.1037132 0.1382843 0.1843790 0.2458387 0.3277849 weights_exponential(alpha = 1, n = 7) #> [1] 0 0 0 0 0 0 1 weights_exponential(alpha = 0, n = 4) #> [1] 0.25 0.25 0.25 0.25  # zooming into an exponential series again gives an exponential series identical(   weights_exponential(alpha = 0.75, n = 5)[1:4] /     sum(weights_exponential(alpha = 0.75, n = 5)[1:4]),   weights_exponential(alpha = 0.75, n = 4) ) #> [1] TRUE"},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized weights_exponential() — weights_exponential_vec","title":"Vectorized weights_exponential() — weights_exponential_vec","text":"Vectorized weights_exponential()","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized weights_exponential() — weights_exponential_vec","text":"","code":"weights_exponential_vec(alphas, n)"},{"path":"http://timradtke.github.io/threedx/reference/weights_exponential_vec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorized weights_exponential() — weights_exponential_vec","text":"","code":"t(vapply(   X = c(1, 0.2, 0.5, 0.8, 0),   FUN = weights_exponential,   n = 50,   FUN.VALUE = numeric(50),   USE.NAMES = FALSE )) #>              [,1]         [,2]         [,3]         [,4]         [,5] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 3.568170e-06 4.460213e-06 5.575266e-06 6.969082e-06 8.711353e-06 #> [3,] 8.881784e-16 1.776357e-15 3.552714e-15 7.105427e-15 1.421085e-14 #> [4,] 4.503600e-35 2.251800e-34 1.125900e-33 5.629500e-33 2.814750e-32 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>              [,6]         [,7]         [,8]         [,9]        [,10] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 1.088919e-05 1.361149e-05 1.701436e-05 2.126795e-05 2.658494e-05 #> [3,] 2.842171e-14 5.684342e-14 1.136868e-13 2.273737e-13 4.547474e-13 #> [4,] 1.407375e-31 7.036874e-31 3.518437e-30 1.759219e-29 8.796093e-29 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>             [,11]        [,12]        [,13]        [,14]        [,15] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 3.323117e-05 4.153897e-05 5.192371e-05 6.490464e-05 8.113080e-05 #> [3,] 9.094947e-13 1.818989e-12 3.637979e-12 7.275958e-12 1.455192e-11 #> [4,] 4.398047e-28 2.199023e-27 1.099512e-26 5.497558e-26 2.748779e-25 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>             [,16]        [,17]        [,18]        [,19]        [,20] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 1.014135e-04 1.267669e-04 1.584586e-04 1.980732e-04 2.475915e-04 #> [3,] 2.910383e-11 5.820766e-11 1.164153e-10 2.328306e-10 4.656613e-10 #> [4,] 1.374390e-24 6.871948e-24 3.435974e-23 1.717987e-22 8.589935e-22 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>             [,21]        [,22]        [,23]        [,24]        [,25] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 3.094894e-04 3.868618e-04 4.835772e-04 6.044715e-04 7.555894e-04 #> [3,] 9.313226e-10 1.862645e-09 3.725290e-09 7.450581e-09 1.490116e-08 #> [4,] 4.294967e-21 2.147484e-20 1.073742e-19 5.368709e-19 2.684355e-18 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>             [,26]        [,27]        [,28]        [,29]        [,30] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 9.444868e-04 1.180608e-03 1.475761e-03 1.844701e-03 2.305876e-03 #> [3,] 2.980232e-08 5.960464e-08 1.192093e-07 2.384186e-07 4.768372e-07 #> [4,] 1.342177e-17 6.710886e-17 3.355443e-16 1.677722e-15 8.388608e-15 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>             [,31]        [,32]        [,33]        [,34]        [,35] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 2.882345e-03 3.602931e-03 4.503664e-03 5.629580e-03 7.036975e-03 #> [3,] 9.536743e-07 1.907349e-06 3.814697e-06 7.629395e-06 1.525879e-05 #> [4,] 4.194304e-14 2.097152e-13 1.048576e-12 5.242880e-12 2.621440e-11 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>             [,36]        [,37]        [,38]        [,39]        [,40] #> [1,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [2,] 8.796219e-03 1.099527e-02 1.374409e-02 1.718011e-02 2.147514e-02 #> [3,] 3.051758e-05 6.103516e-05 1.220703e-04 2.441406e-04 4.882813e-04 #> [4,] 1.310720e-10 6.553600e-10 3.276800e-09 1.638400e-08 8.192000e-08 #> [5,] 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 2.000000e-02 #>             [,41]       [,42]      [,43]      [,44]      [,45]      [,46] #> [1,] 0.0000000000 0.000000000 0.00000000 0.00000000 0.00000000 0.00000000 #> [2,] 0.0268439287 0.033554911 0.04194364 0.05242955 0.06553694 0.08192117 #> [3,] 0.0009765625 0.001953125 0.00390625 0.00781250 0.01562500 0.03125000 #> [4,] 0.0000004096 0.000002048 0.00001024 0.00005120 0.00025600 0.00128000 #> [5,] 0.0200000000 0.020000000 0.02000000 0.02000000 0.02000000 0.02000000 #>          [,47]     [,48]     [,49]     [,50] #> [1,] 0.0000000 0.0000000 0.0000000 1.0000000 #> [2,] 0.1024015 0.1280018 0.1600023 0.2000029 #> [3,] 0.0625000 0.1250000 0.2500000 0.5000000 #> [4,] 0.0064000 0.0320000 0.1600000 0.8000000 #> [5,] 0.0200000 0.0200000 0.0200000 0.0200000"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive seasonal exponential weights — weights_seasonal","title":"Derive seasonal exponential weights — weights_seasonal","text":"Assigns largest weight season period length period_length, exponentially decaying weights neighboring seasons. recent value resulting weights vector assigned second-highest weight direct neighbor current season. See examples illustrations .","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive seasonal exponential weights — weights_seasonal","text":"","code":"weights_seasonal(alpha_seasonal, n, period_length)"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive seasonal exponential weights — weights_seasonal","text":"alpha_seasonal value 0 1 determines quick exponential decay weights n number weights create; usually equal number observations time series period_length length seasonal period modeled","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive seasonal exponential weights — weights_seasonal","text":"numeric vector n values 0 1 sum 1","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive seasonal exponential weights — weights_seasonal","text":"","code":"round(   weights_seasonal(alpha_seasonal = 0.25, n = 8, period_length = 7L),   3 ) #> [1] 0.144 0.192 0.144 0.108 0.081 0.081 0.108 0.144  round(   weights_seasonal(alpha_seasonal = 0.75, n = 27, period_length = 12L),   3 ) #>  [1] 0.004 0.017 0.068 0.273 0.068 0.017 0.004 0.001 0.000 0.000 0.000 0.001 #> [13] 0.004 0.017 0.068 0.273 0.068 0.017 0.004 0.001 0.000 0.000 0.000 0.001 #> [25] 0.004 0.017 0.068  # \"seasonal mean\" weights weights_seasonal(alpha_seasonal = 1, n = 30, period_length = 7L) #>  [1] 0.00 0.00 0.25 0.00 0.00 0.00 0.00 0.00 0.00 0.25 0.00 0.00 0.00 0.00 0.00 #> [16] 0.00 0.25 0.00 0.00 0.00 0.00 0.00 0.00 0.25 0.00 0.00 0.00 0.00 0.00 0.00  # mean weights weights_seasonal(alpha_seasonal = 0, n = 30, period_length = 7L) #>  [1] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #>  [7] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #> [13] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #> [19] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #> [25] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive weights with seasonal exponential decay — weights_seasonal_decay","title":"Derive weights with seasonal exponential decay — weights_seasonal_decay","text":"Assigns weight season within period, exponentially decays across periods. example, period length 12, recent 12 weights equal, higher next 12 weights follow. See examples illustration idea.","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive weights with seasonal exponential decay — weights_seasonal_decay","text":"","code":"weights_seasonal_decay(alpha_seasonal_decay, n, period_length)"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive weights with seasonal exponential decay — weights_seasonal_decay","text":"alpha_seasonal_decay value 0 1 determines quick exponential decay weights n number weights create; usually equal number observations time series period_length length seasonal period modeled","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive weights with seasonal exponential decay — weights_seasonal_decay","text":"numeric vector n values 0 1 sum 1","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive weights with seasonal exponential decay — weights_seasonal_decay","text":"","code":"round(   weights_seasonal_decay(     alpha_seasonal_decay = 0.5, n = 19L, period_length = 7L   ),   2 ) #>  [1] 0.02 0.02 0.02 0.02 0.02 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.09 0.09 0.09 #> [16] 0.09 0.09 0.09 0.09  weights_seasonal_decay(alpha_seasonal_decay = 1, n = 19L, period_length = 7L) #>  [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #>  [8] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.1428571 0.1428571 #> [15] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 weights_seasonal_decay(alpha_seasonal_decay = 0, n = 19L, period_length = 7L) #>  [1] 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 #>  [7] 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 #> [13] 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 #> [19] 0.05263158  # no full period weights_seasonal_decay(alpha_seasonal_decay = 1, n = 4L, period_length = 7L) #> [1] 0.25 0.25 0.25 0.25"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized weights_seasonal_decay() — weights_seasonal_decay_vec","title":"Vectorized weights_seasonal_decay() — weights_seasonal_decay_vec","text":"Vectorized weights_seasonal_decay()","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized weights_seasonal_decay() — weights_seasonal_decay_vec","text":"","code":"weights_seasonal_decay_vec(alphas_seasonal_decay, n, period_length)"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_decay_vec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorized weights_seasonal_decay() — weights_seasonal_decay_vec","text":"","code":"t(vapply(   X = c(1, 0.2, 0.5, 0.8, 0),   FUN = weights_seasonal_decay,   n = 50,   period_length = 12,   FUN.VALUE = numeric(50),   USE.NAMES = FALSE )) #>              [,1]         [,2]         [,3]         [,4]         [,5] #> [1,] 0.0000000000 0.0000000000 0.0000000000 0.0000000000 0.0000000000 #> [2,] 0.0113014303 0.0113014303 0.0141267879 0.0141267879 0.0141267879 #> [3,] 0.0027624309 0.0027624309 0.0055248619 0.0055248619 0.0055248619 #> [4,] 0.0001068148 0.0001068148 0.0005340739 0.0005340739 0.0005340739 #> [5,] 0.0200000000 0.0200000000 0.0200000000 0.0200000000 0.0200000000 #>              [,6]         [,7]         [,8]         [,9]        [,10] #> [1,] 0.0000000000 0.0000000000 0.0000000000 0.0000000000 0.0000000000 #> [2,] 0.0141267879 0.0141267879 0.0141267879 0.0141267879 0.0141267879 #> [3,] 0.0055248619 0.0055248619 0.0055248619 0.0055248619 0.0055248619 #> [4,] 0.0005340739 0.0005340739 0.0005340739 0.0005340739 0.0005340739 #> [5,] 0.0200000000 0.0200000000 0.0200000000 0.0200000000 0.0200000000 #>             [,11]        [,12]        [,13]        [,14]      [,15]      [,16] #> [1,] 0.0000000000 0.0000000000 0.0000000000 0.0000000000 0.00000000 0.00000000 #> [2,] 0.0141267879 0.0141267879 0.0141267879 0.0141267879 0.01765848 0.01765848 #> [3,] 0.0055248619 0.0055248619 0.0055248619 0.0055248619 0.01104972 0.01104972 #> [4,] 0.0005340739 0.0005340739 0.0005340739 0.0005340739 0.00267037 0.00267037 #> [5,] 0.0200000000 0.0200000000 0.0200000000 0.0200000000 0.02000000 0.02000000 #>           [,17]      [,18]      [,19]      [,20]      [,21]      [,22] #> [1,] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> [2,] 0.01765848 0.01765848 0.01765848 0.01765848 0.01765848 0.01765848 #> [3,] 0.01104972 0.01104972 0.01104972 0.01104972 0.01104972 0.01104972 #> [4,] 0.00267037 0.00267037 0.00267037 0.00267037 0.00267037 0.00267037 #> [5,] 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 #>           [,23]      [,24]      [,25]      [,26]      [,27]      [,28] #> [1,] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> [2,] 0.01765848 0.01765848 0.01765848 0.01765848 0.02207311 0.02207311 #> [3,] 0.01104972 0.01104972 0.01104972 0.01104972 0.02209945 0.02209945 #> [4,] 0.00267037 0.00267037 0.00267037 0.00267037 0.01335185 0.01335185 #> [5,] 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 #>           [,29]      [,30]      [,31]      [,32]      [,33]      [,34] #> [1,] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> [2,] 0.02207311 0.02207311 0.02207311 0.02207311 0.02207311 0.02207311 #> [3,] 0.02209945 0.02209945 0.02209945 0.02209945 0.02209945 0.02209945 #> [4,] 0.01335185 0.01335185 0.01335185 0.01335185 0.01335185 0.01335185 #> [5,] 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 #>           [,35]      [,36]      [,37]      [,38]      [,39]      [,40] #> [1,] 0.00000000 0.00000000 0.00000000 0.00000000 0.08333333 0.08333333 #> [2,] 0.02207311 0.02207311 0.02207311 0.02207311 0.02759138 0.02759138 #> [3,] 0.02209945 0.02209945 0.02209945 0.02209945 0.04419890 0.04419890 #> [4,] 0.01335185 0.01335185 0.01335185 0.01335185 0.06675924 0.06675924 #> [5,] 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 #>           [,41]      [,42]      [,43]      [,44]      [,45]      [,46] #> [1,] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 #> [2,] 0.02759138 0.02759138 0.02759138 0.02759138 0.02759138 0.02759138 #> [3,] 0.04419890 0.04419890 0.04419890 0.04419890 0.04419890 0.04419890 #> [4,] 0.06675924 0.06675924 0.06675924 0.06675924 0.06675924 0.06675924 #> [5,] 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 0.02000000 #>           [,47]      [,48]      [,49]      [,50] #> [1,] 0.08333333 0.08333333 0.08333333 0.08333333 #> [2,] 0.02759138 0.02759138 0.02759138 0.02759138 #> [3,] 0.04419890 0.04419890 0.04419890 0.04419890 #> [4,] 0.06675924 0.06675924 0.06675924 0.06675924 #> [5,] 0.02000000 0.02000000 0.02000000 0.02000000  threedx:::weights_seasonal_decay_vec(   alphas_seasonal_decay = c(0.2, 0.5, 0.8), n = 50, period_length = 12L ) #>              [,1]         [,2]         [,3]         [,4]         [,5] #> [1,] 0.0113014303 0.0113014303 0.0141267879 0.0141267879 0.0141267879 #> [2,] 0.0027624309 0.0027624309 0.0055248619 0.0055248619 0.0055248619 #> [3,] 0.0001068148 0.0001068148 0.0005340739 0.0005340739 0.0005340739 #>              [,6]         [,7]         [,8]         [,9]        [,10] #> [1,] 0.0141267879 0.0141267879 0.0141267879 0.0141267879 0.0141267879 #> [2,] 0.0055248619 0.0055248619 0.0055248619 0.0055248619 0.0055248619 #> [3,] 0.0005340739 0.0005340739 0.0005340739 0.0005340739 0.0005340739 #>             [,11]        [,12]        [,13]        [,14]      [,15]      [,16] #> [1,] 0.0141267879 0.0141267879 0.0141267879 0.0141267879 0.01765848 0.01765848 #> [2,] 0.0055248619 0.0055248619 0.0055248619 0.0055248619 0.01104972 0.01104972 #> [3,] 0.0005340739 0.0005340739 0.0005340739 0.0005340739 0.00267037 0.00267037 #>           [,17]      [,18]      [,19]      [,20]      [,21]      [,22] #> [1,] 0.01765848 0.01765848 0.01765848 0.01765848 0.01765848 0.01765848 #> [2,] 0.01104972 0.01104972 0.01104972 0.01104972 0.01104972 0.01104972 #> [3,] 0.00267037 0.00267037 0.00267037 0.00267037 0.00267037 0.00267037 #>           [,23]      [,24]      [,25]      [,26]      [,27]      [,28] #> [1,] 0.01765848 0.01765848 0.01765848 0.01765848 0.02207311 0.02207311 #> [2,] 0.01104972 0.01104972 0.01104972 0.01104972 0.02209945 0.02209945 #> [3,] 0.00267037 0.00267037 0.00267037 0.00267037 0.01335185 0.01335185 #>           [,29]      [,30]      [,31]      [,32]      [,33]      [,34] #> [1,] 0.02207311 0.02207311 0.02207311 0.02207311 0.02207311 0.02207311 #> [2,] 0.02209945 0.02209945 0.02209945 0.02209945 0.02209945 0.02209945 #> [3,] 0.01335185 0.01335185 0.01335185 0.01335185 0.01335185 0.01335185 #>           [,35]      [,36]      [,37]      [,38]      [,39]      [,40] #> [1,] 0.02207311 0.02207311 0.02207311 0.02207311 0.02759138 0.02759138 #> [2,] 0.02209945 0.02209945 0.02209945 0.02209945 0.04419890 0.04419890 #> [3,] 0.01335185 0.01335185 0.01335185 0.01335185 0.06675924 0.06675924 #>           [,41]      [,42]      [,43]      [,44]      [,45]      [,46] #> [1,] 0.02759138 0.02759138 0.02759138 0.02759138 0.02759138 0.02759138 #> [2,] 0.04419890 0.04419890 0.04419890 0.04419890 0.04419890 0.04419890 #> [3,] 0.06675924 0.06675924 0.06675924 0.06675924 0.06675924 0.06675924 #>           [,47]      [,48]      [,49]      [,50] #> [1,] 0.02759138 0.02759138 0.02759138 0.02759138 #> [2,] 0.04419890 0.04419890 0.04419890 0.04419890 #> [3,] 0.06675924 0.06675924 0.06675924 0.06675924"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized weights_seasonal() — weights_seasonal_vec","title":"Vectorized weights_seasonal() — weights_seasonal_vec","text":"Vectorized weights_seasonal()","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized weights_seasonal() — weights_seasonal_vec","text":"","code":"weights_seasonal_vec(alphas_seasonal, n, period_length)"},{"path":"http://timradtke.github.io/threedx/reference/weights_seasonal_vec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorized weights_seasonal() — weights_seasonal_vec","text":"","code":"t(vapply(   X = c(1, 0.2, 0.5, 0.8, 0),   FUN = weights_seasonal,   n = 50,   period_length = 12,   FUN.VALUE = numeric(50),   USE.NAMES = FALSE )) #>             [,1]       [,2]       [,3]       [,4]        [,5]        [,6] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>             [,7]         [,8]         [,9]        [,10]       [,11]       [,12] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,13]      [,14]      [,15]      [,16]       [,17]       [,18] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>            [,19]        [,20]        [,21]        [,22]       [,23]       [,24] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,25]      [,26]      [,27]      [,28]       [,29]       [,30] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>            [,31]        [,32]        [,33]        [,34]       [,35]       [,36] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,37]      [,38]      [,39]      [,40]       [,41]       [,42] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>            [,43]        [,44]        [,45]        [,46]       [,47]       [,48] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,49]      [,50] #> [1,] 0.000000000 0.00000000 #> [2,] 0.022854844 0.02856856 #> [3,] 0.019900498 0.03980100 #> [4,] 0.006410651 0.03205325 #> [5,] 0.020000000 0.02000000  threedx:::weights_seasonal_vec(   alphas_seasonal = c(1, 0.2, 0.5, 0.8, 0), n = 50, period_length = 12L ) #>             [,1]       [,2]       [,3]       [,4]        [,5]        [,6] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>             [,7]         [,8]         [,9]        [,10]       [,11]       [,12] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,13]      [,14]      [,15]      [,16]       [,17]       [,18] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>            [,19]        [,20]        [,21]        [,22]       [,23]       [,24] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,25]      [,26]      [,27]      [,28]       [,29]       [,30] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>            [,31]        [,32]        [,33]        [,34]       [,35]       [,36] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,37]      [,38]      [,39]      [,40]       [,41]       [,42] #> [1,] 0.000000000 0.00000000 0.25000000 0.00000000 0.000000000 0.000000000 #> [2,] 0.022854844 0.02856856 0.03571069 0.02856856 0.022854844 0.018283875 #> [3,] 0.019900498 0.03980100 0.07960199 0.03980100 0.019900498 0.009950249 #> [4,] 0.006410651 0.03205325 0.16026627 0.03205325 0.006410651 0.001282130 #> [5,] 0.020000000 0.02000000 0.02000000 0.02000000 0.020000000 0.020000000 #>            [,43]        [,44]        [,45]        [,46]       [,47]       [,48] #> [1,] 0.000000000 0.000000e+00 0.000000e+00 0.000000e+00 0.000000000 0.000000000 #> [2,] 0.014627100 1.170168e-02 9.361344e-03 1.170168e-02 0.014627100 0.018283875 #> [3,] 0.004975124 2.487562e-03 1.243781e-03 2.487562e-03 0.004975124 0.009950249 #> [4,] 0.000256426 5.128521e-05 1.025704e-05 5.128521e-05 0.000256426 0.001282130 #> [5,] 0.020000000 2.000000e-02 2.000000e-02 2.000000e-02 0.020000000 0.020000000 #>            [,49]      [,50] #> [1,] 0.000000000 0.00000000 #> [2,] 0.022854844 0.02856856 #> [3,] 0.019900498 0.03980100 #> [4,] 0.006410651 0.03205325 #> [5,] 0.020000000 0.02000000"},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive three-dimensional exponential (3DX) weights — weights_threedx","title":"Derive three-dimensional exponential (3DX) weights — weights_threedx","text":"Assigns weights decay three different directions determined combination weights_exponential(), weights_seasonal(), weights_seasonal_decay().","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive three-dimensional exponential (3DX) weights — weights_threedx","text":"","code":"weights_threedx(alpha, alpha_seasonal, alpha_seasonal_decay, n, period_length)"},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive three-dimensional exponential (3DX) weights — weights_threedx","text":"alpha smoothing factor passed weights_exponential() determines overall monotonic exponential weight component alpha_seasonal smoothing factor passed weights_seasonal() determines exponential weighting within seasonal period alpha_seasonal_decay smoothing factor passed weights_seasonal_decay() determines exponential weighting seasonal periods n number weights create; usually equal number observations time series period_length length seasonal period modeled","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive three-dimensional exponential (3DX) weights — weights_threedx","text":"numeric vector n values 0 1 sum 1","code":""},{"path":[]},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive three-dimensional exponential (3DX) weights — weights_threedx","text":"","code":"weights <- weights_threedx(   alpha = 0.01,   alpha_seasonal = 0.05,   alpha_seasonal_decay = 0.01,   n = 17,   period_length = 5 )  print(weights) #>  [1] 0.05115383 0.05439003 0.05841513 0.05605492 0.05379007 0.05433341 #>  [7] 0.05777077 0.06204605 0.05953914 0.05713352 0.05771063 0.06136164 #> [13] 0.06590267 0.06323993 0.06068478 0.06129776 0.06517572  if (require(\"ggplot2\")) {   ggplot2::ggplot(     data.frame(index = seq_along(weights), weight = weights),     ggplot2::aes(x = index, y = weight)   ) +     ggplot2::geom_col() }   # random walk forecast weights_threedx(   alpha = 1,   alpha_seasonal = 0,   alpha_seasonal_decay = 1,   n = 30,   period_length = 12 ) #>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1  # mean forecast weights_threedx(   alpha = 0,   alpha_seasonal = 0,   alpha_seasonal_decay = 0,   n = 30,   period_length = 12 ) #>  [1] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #>  [7] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #> [13] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #> [19] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 #> [25] 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333  # seasonal mean forecast weights_threedx(   alpha = 0,   alpha_seasonal = 1,   alpha_seasonal_decay = 0,   n = 30,   period_length = 12 ) #>  [1] 0.0 0.0 0.0 0.0 0.0 0.0 0.5 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.5 #> [20] 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0  # seasonal naive forecast weights_threedx(   alpha = 0,   alpha_seasonal = 1,   alpha_seasonal_decay = 1,   n = 30,   period_length = 12 ) #>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0  # last year's mean forecast weights_threedx(   alpha = 0,   alpha_seasonal = 0,   alpha_seasonal_decay = 1,   n = 30,   period_length = 12 ) #>  [1] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #>  [7] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> [13] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 #> [19] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 #> [25] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333"},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized weights_threedx() — weights_threedx_vec","title":"Vectorized weights_threedx() — weights_threedx_vec","text":"Vectorized weights_threedx()","code":""},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized weights_threedx() — weights_threedx_vec","text":"","code":"weights_threedx_vec(   alphas,   alphas_seasonal,   alphas_seasonal_decay,   n,   period_length )"},{"path":"http://timradtke.github.io/threedx/reference/weights_threedx_vec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorized weights_threedx() — weights_threedx_vec","text":"","code":"threedx:::weights_threedx_vec(   alphas = c(0, 0.2, 0.5, 0.8, 1),   alphas_seasonal = c(0.1, 0.3, 0.55, 1, 0.25),   alphas_seasonal_decay = c(0.11, 0.01, 0.02, 0.05, 0.1),   n = 50,   period_length = 7 ) #>              [,1]         [,2]         [,3]         [,4]         [,5] #> [1,] 1.318203e-02 1.645697e-02 1.481128e-02 1.333015e-02 1.199713e-02 #> [2,] 4.232186e-06 7.633813e-06 6.679587e-06 5.844638e-06 5.114058e-06 #> [3,] 1.096958e-15 4.974865e-15 4.477378e-15 4.029640e-15 3.626676e-15 #> [4,] 0.000000e+00 3.232929e-30 0.000000e+00 0.000000e+00 0.000000e+00 #> [5,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>              [,6]         [,7]         [,8]         [,9]        [,10] #> [1,] 1.199713e-02 1.333015e-02 1.481128e-02 1.849098e-02 1.664188e-02 #> [2,] 6.392573e-06 1.141531e-05 2.038448e-05 3.676854e-05 3.217248e-05 #> [3,] 7.253353e-15 3.223712e-14 1.432761e-13 6.497782e-13 5.848004e-13 #> [4,] 0.000000e+00 0.000000e+00 0.000000e+00 2.658659e-25 0.000000e+00 #> [5,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>             [,11]        [,12]        [,13]        [,14]        [,15] #> [1,] 1.497769e-02 1.347992e-02 1.347992e-02 1.497769e-02 1.664188e-02 #> [2,] 2.815092e-05 2.463205e-05 3.079006e-05 5.498226e-05 9.818260e-05 #> [3,] 5.263204e-13 4.736883e-13 9.473767e-13 4.210563e-12 1.871361e-11 #> [4,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [5,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>             [,16]        [,17]        [,18]        [,19]        [,20] #> [1,] 2.077638e-02 1.869874e-02 1.682887e-02 1.514598e-02 1.514598e-02 #> [2,] 1.770970e-04 1.549599e-04 1.355899e-04 1.186412e-04 1.483015e-04 #> [3,] 8.486899e-11 7.638210e-11 6.874389e-11 6.186950e-11 1.237390e-10 #> [4,] 2.186397e-20 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [5,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>             [,21]        [,22]        [,23]        [,24]        [,25] #> [1,] 1.682887e-02 1.869874e-02 2.334425e-02 2.100982e-02 1.890884e-02 #> [2,] 2.648241e-04 4.729001e-04 8.529945e-04 7.463702e-04 6.530739e-04 #> [3,] 5.499511e-10 2.444227e-09 1.108493e-08 9.976437e-09 8.978793e-09 #> [4,] 0.000000e+00 0.000000e+00 1.798024e-15 0.000000e+00 0.000000e+00 #> [5,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>             [,26]        [,27]        [,28]        [,29]        [,30] #> [1,] 1.701796e-02 1.701796e-02 1.890884e-02 2.100982e-02 2.622949e-02 #> [2,] 5.714397e-04 7.142996e-04 1.275535e-03 2.277741e-03 4.108479e-03 #> [3,] 8.080914e-09 1.616183e-08 7.183035e-08 3.192460e-07 1.447828e-06 #> [4,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.478638e-10 #> [5,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>             [,31]        [,32]        [,33]        [,34]        [,35] #> [1,] 2.360654e-02 2.124589e-02 1.912130e-02 1.912130e-02 2.124589e-02 #> [2,] 3.594919e-03 3.145555e-03 2.752360e-03 3.440450e-03 6.143661e-03 #> [3,] 1.303045e-06 1.172740e-06 1.055466e-06 2.110933e-06 9.381923e-06 #> [4,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #> [5,] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 #>             [,36]        [,37]        [,38]        [,39]        [,40] #> [1,] 2.360654e-02 2.947134e-02 0.0265242075 0.0238717868 0.0214846081 #> [2,] 1.097082e-02 1.978864e-02 0.0173150624 0.0151506796 0.0132568447 #> [3,] 4.169743e-05 1.891040e-04 0.0001701936 0.0001531742 0.0001378568 #> [4,] 0.000000e+00 1.215985e-05 0.0000000000 0.0000000000 0.0000000000 #> [5,] 0.000000e+00 0.000000e+00 0.0000000000 0.0000000000 0.0000000000 #>             [,41]       [,42]       [,43]      [,44]      [,45]      [,46] #> [1,] 0.0214846081 0.023871787 0.026524208 0.03311387 0.02980248 0.02682223 #> [2,] 0.0165710558 0.029591171 0.052841377 0.09531273 0.08339864 0.07297381 #> [3,] 0.0002757136 0.001225394 0.005446196 0.02469930 0.02222937 0.02000643 #> [4,] 0.0000000000 0.000000000 0.000000000 0.99998784 0.00000000 0.00000000 #> [5,] 0.0000000000 0.000000000 0.000000000 0.00000000 0.00000000 0.00000000 #>           [,47]      [,48]      [,49]      [,50] #> [1,] 0.02414001 0.02414001 0.02682223 0.02980248 #> [2,] 0.06385208 0.07981510 0.14252697 0.25451245 #> [3,] 0.01800579 0.03601158 0.16005146 0.71133982 #> [4,] 0.00000000 0.00000000 0.00000000 0.00000000 #> [5,] 0.00000000 0.00000000 0.00000000 1.00000000"}]
